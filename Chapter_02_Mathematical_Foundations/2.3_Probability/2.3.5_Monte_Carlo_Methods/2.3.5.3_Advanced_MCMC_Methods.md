# 2.3.5.3 Advanced MCMC Methods

## Advanced Markov Chain Monte Carlo Methods

While basic MCMC methods like Metropolis-Hastings and Gibbs sampling are powerful, they can face challenges with high-dimensional, complex, or multimodal distributions. Advanced MCMC methods have been developed to address these limitations, offering improved efficiency, scalability, and robustness. In this section, we'll explore several advanced MCMC techniques that are particularly relevant for machine learning applications.

## Hamiltonian Monte Carlo (HMC)

### Motivation and Concept

**Hamiltonian Monte Carlo** (also known as Hybrid Monte Carlo) leverages concepts from physics to make MCMC sampling more efficient, especially in high-dimensional spaces. The key idea is to use the gradient of the target distribution to guide the proposals, allowing for larger moves while maintaining high acceptance rates.

HMC introduces an auxiliary momentum variable p for each position variable q (the original parameters), creating a joint distribution:

$$p(q, p) = p(q) p(p) = p(q) \mathcal{N}(p | 0, M)$$

where p(q) is the target distribution and p(p) is typically a Gaussian distribution with mass matrix M.

### Hamiltonian Dynamics

HMC simulates the evolution of a physical system according to Hamiltonian dynamics:

$$H(q, p) = -\log p(q, p) = -\log p(q) - \log p(p) = U(q) + K(p)$$

where:
- H(q, p) is the Hamiltonian (total energy)
- U(q) = -log p(q) is the potential energy
- K(p) = -log p(p) is the kinetic energy

The system evolves according to:

$$\frac{dq}{dt} = \frac{\partial H}{\partial p} = \frac{\partial K}{\partial p}$$

$$\frac{dp}{dt} = -\frac{\partial H}{\partial q} = -\frac{\partial U}{\partial q} = \nabla \log p(q)$$

### The HMC Algorithm

1. Initialize position q⁰
2. For t = 1, 2, ..., T:
   a. Sample momentum p ~ N(0, M)
   b. Simulate Hamiltonian dynamics for L steps using the leapfrog integrator:
      - For i = 1, 2, ..., L:
        - p ← p - (ε/2) ∇U(q)
        - q ← q + ε M⁻¹p
        - p ← p - (ε/2) ∇U(q)
   c. Accept or reject the proposal (q*, p*) with probability:
      $$\alpha = \min(1, \exp(H(q^t, p) - H(q^*, p^*)))$$
   d. If accepted, set q^{t+1} = q*; otherwise, set q^{t+1} = q^t

### Advantages and Challenges

**Advantages**:
- Efficient exploration of high-dimensional spaces
- Reduced random walk behavior
- Better handling of correlated parameters

**Challenges**:
- Requires gradient computation
- Sensitive to step size ε and number of steps L
- May struggle with multimodal distributions

### Example: HMC for a Multivariate Normal

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

def log_density(q, mu, sigma_inv):
    """Log density of a multivariate normal distribution (up to a constant)"""
    delta = q - mu
    return -0.5 * np.dot(delta, np.dot(sigma_inv, delta))

def grad_log_density(q, mu, sigma_inv):
    """Gradient of the log density"""
    return -np.dot(sigma_inv, q - mu)

def hamiltonian_monte_carlo(n_samples, n_steps, step_size, mu, sigma):
    """Hamiltonian Monte Carlo for sampling from a multivariate normal"""
    # Dimension of the distribution
    d = len(mu)
    
    # Inverse covariance matrix
    sigma_inv = np.linalg.inv(sigma)
    
    # Initialize samples
    samples = np.zeros((n_samples, d))
    q = np.zeros(d)  # Start at the origin
    
    # Run the Markov chain
    for i in range(n_samples):
        # Sample momentum
        p = np.random.normal(0, 1, d)
        
        # Store initial position and momentum
        q_current = q.copy()
        p_current = p.copy()
        
        # Initial Hamiltonian
        current_H = -log_density(q_current, mu, sigma_inv) + 0.5 * np.sum(p_current**2)
        
        # Leapfrog integration
        p -= 0.5 * step_size * grad_log_density(q, mu, sigma_inv)
        
        for j in range(n_steps):
            q += step_size * p
            if j < n_steps - 1:
                p -= step_size * grad_log_density(q, mu, sigma_inv)
        
        p -= 0.5 * step_size * grad_log_density(q, mu, sigma_inv)
        
        # Negate momentum to make the proposal symmetric
        p = -p
        
        # Proposed Hamiltonian
        proposed_H = -log_density(q, mu, sigma_inv) + 0.5 * np.sum(p**2)
        
        # Metropolis acceptance step
        if np.random.uniform() < np.exp(current_H - proposed_H):
            # Accept
            pass
        else:
            # Reject
            q = q_current
        
        # Store the sample
        samples[i] = q
    
    return samples

# Parameters for bivariate normal
mu = np.array([1.0, 2.0])
sigma = np.array([[1.0, 0.8], [0.8, 1.0]])  # Correlation = 0.8

# Generate samples
n_samples = 5000
burn_in = 1000
step_size = 0.1
n_steps = 20

samples = hamiltonian_monte_carlo(n_samples + burn_in, n_steps, step_size, mu, sigma)
samples = samples[burn_in:]  # Discard burn-in period

# Plot the results
plt.figure(figsize=(10, 8))

# Scatter plot of samples
plt.scatter(samples[:, 0], samples[:, 1], alpha=0.5)
plt.xlabel('q1')
plt.ylabel('q2')
plt.title('Hamiltonian Monte Carlo Sampling')
plt.grid(True)

# Compare with direct sampling
direct_samples = np.random.multivariate_normal(mu, sigma, n_samples)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.scatter(direct_samples[:, 0], direct_samples[:, 1], alpha=0.5)
plt.xlabel('q1')
plt.ylabel('q2')
plt.title('Direct Sampling')
plt.grid(True)

plt.subplot(1, 2, 2)
plt.scatter(samples[:, 0], samples[:, 1], alpha=0.5)
plt.xlabel('q1')
plt.ylabel('q2')
plt.title('HMC Sampling')
plt.grid(True)

plt.tight_layout()
plt.show()
```

## No-U-Turn Sampler (NUTS)

### Motivation and Concept

The **No-U-Turn Sampler (NUTS)** is an extension of HMC that automatically tunes the number of leapfrog steps L, addressing one of the main challenges of HMC. NUTS adaptively selects the path length to avoid doubling back on itself (hence "no U-turn"), which improves efficiency.

### Key Innovations

1. **Adaptive Path Length**: Dynamically determines the number of leapfrog steps
2. **Recursive Doubling**: Builds a binary tree of states by doubling the trajectory length
3. **Termination Criterion**: Stops when the trajectory starts to turn back on itself
4. **Multinomial Sampling**: Samples from all valid points along the trajectory

### Advantages

- Eliminates the need to manually tune the number of leapfrog steps
- Often more efficient than standard HMC
- Widely used in probabilistic programming languages like Stan and PyMC

## Slice Sampling

### Motivation and Concept

**Slice sampling** is an adaptive MCMC method that automatically adjusts to the local shape of the distribution. The key idea is to sample uniformly from the region under the probability density function.

### The Slice Sampling Algorithm

1. Given the current state x_t:
   a. Draw a vertical level u ~ Uniform(0, f(x_t))
   b. Define a horizontal "slice" S = {x : f(x) ≥ u}
   c. Sample the next state x_{t+1} uniformly from the slice S

### Practical Implementation

In practice, sampling uniformly from the slice is challenging. Common approaches include:
- **Stepping-out**: Expand an initial interval until its endpoints are outside the slice
- **Shrinkage**: Iteratively shrink an interval containing the slice

### Advantages

- Adaptive to the local shape of the distribution
- No need to tune a proposal distribution
- Works well for univariate distributions and as a component in Gibbs sampling

### Example: Slice Sampling for a Mixture of Gaussians

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

def target_pdf(x):
    """Target distribution: mixture of two Gaussians"""
    return 0.3 * stats.norm.pdf(x, -3, 1) + 0.7 * stats.norm.pdf(x, 3, 1)

def slice_sampling(n_samples, width=10.0):
    """Slice sampling for the target distribution"""
    samples = np.zeros(n_samples)
    x = 0.0  # Initial point
    
    for i in range(n_samples):
        # Draw a vertical level
        u = np.random.uniform(0, target_pdf(x))
        
        # Find the horizontal slice
        # Stepping out procedure
        lower = x - np.random.uniform(0, width)
        upper = lower + width
        
        # Expand the interval until the endpoints are outside the slice
        while target_pdf(lower) > u:
            lower -= width
        while target_pdf(upper) > u:
            upper += width
        
        # Sample from the slice
        # Shrinkage procedure
        while True:
            x_new = np.random.uniform(lower, upper)
            if target_pdf(x_new) > u:
                x = x_new  # Accept
                break
            elif x_new < x:
                lower = x_new  # Shrink from left
            else:
                upper = x_new  # Shrink from right
        
        samples[i] = x
    
    return samples

# Generate samples
n_samples = 5000
burn_in = 1000
samples = slice_sampling(n_samples + burn_in)
samples = samples[burn_in:]  # Discard burn-in period

# Plot the results
plt.figure(figsize=(12, 6))

# Plot the target distribution
x = np.linspace(-8, 8, 1000)
plt.plot(x, target_pdf(x), 'r-', lw=2, label='Target PDF')

# Plot the histogram of samples
plt.hist(samples, bins=50, density=True, alpha=0.7, label='Slice Sampling')

plt.xlabel('x')
plt.ylabel('Density')
plt.title('Slice Sampling for a Mixture of Gaussians')
plt.legend()
plt.grid(True)
plt.show()

# Plot the trace of the chain
plt.figure(figsize=(12, 4))
plt.plot(samples[:500], 'b-')
plt.xlabel('Iteration')
plt.ylabel('Sample Value')
plt.title('Trace of the Slice Sampling Chain (first 500 samples after burn-in)')
plt.grid(True)
plt.show()
```

## Reversible Jump MCMC (RJMCMC)

### Motivation and Concept

**Reversible Jump MCMC** extends MCMC to handle models with varying dimensions, such as model selection problems where the number of parameters changes across models.

### Key Idea

RJMCMC allows "jumps" between parameter spaces of different dimensions while maintaining detailed balance. This is achieved by introducing dimension-matching variables and appropriate Jacobian terms in the acceptance ratio.

### Applications

- **Bayesian Model Selection**: Sampling from the posterior distribution over models
- **Changepoint Detection**: Inferring the number and location of changepoints
- **Mixture Models**: Determining the number of components

## Sequential Monte Carlo (SMC)

### Motivation and Concept

**Sequential Monte Carlo** methods (also known as particle filters) are designed for sequential data, where observations arrive over time and the posterior distribution is updated incrementally.

### The SMC Algorithm

1. Initialize particles {x₁⁽¹⁾, x₁⁽²⁾, ..., x₁⁽ᴺ⁾} from the prior p(x₁)
2. For t = 2, 3, ..., T:
   a. Propagate particles: Sample x_t⁽ⁱ⁾ ~ p(x_t | x_{t-1}⁽ⁱ⁾)
   b. Weight particles: w_t⁽ⁱ⁾ ∝ p(y_t | x_t⁽ⁱ⁾)
   c. Resample particles according to weights
   d. Compute posterior estimates using the weighted particles

### Advantages

- Handles sequential data naturally
- Works well for non-linear, non-Gaussian state-space models
- Can adapt to changing distributions over time

### Applications

- **Object Tracking**: Following objects in video sequences
- **Robot Localization**: Estimating a robot's position over time
- **Time Series Analysis**: Forecasting and filtering in dynamic models

## Parallel Tempering

### Motivation and Concept

**Parallel tempering** (also known as replica exchange) is designed to help MCMC methods escape local modes in multimodal distributions. It runs multiple chains at different "temperatures" and allows exchanges between them.

### The Parallel Tempering Algorithm

1. Initialize M chains at different temperatures T₁ < T₂ < ... < T_M
2. For each iteration:
   a. Update each chain using a standard MCMC method
   b. Propose swaps between adjacent chains i and i+1 with probability:
      $$\alpha = \min(1, \exp((\beta_i - \beta_{i+1})(U(x_{i+1}) - U(x_i))))$$
      where β_i = 1/T_i and U(x) = -log p(x)

### Advantages

- Improved exploration of multimodal distributions
- Better mixing properties
- Parallelizable across multiple processors

### Applications

- **Bayesian Mixture Models**: Handling label switching and multimodality
- **Protein Folding**: Exploring complex energy landscapes
- **Image Segmentation**: Dealing with multiple local optima

## Applications in Machine Learning

### 1. Bayesian Neural Networks

Advanced MCMC methods are used to sample from the posterior distribution over neural network weights:

- **HMC and NUTS**: Efficient sampling in high-dimensional weight spaces
- **Stochastic Gradient MCMC**: Scaling to large datasets using mini-batches

### 2. Gaussian Process Models

MCMC is used for hyperparameter inference in Gaussian process models:

- **Slice Sampling**: For univariate hyperparameters
- **HMC**: For joint sampling of hyperparameters

### 3. Topic Models

MCMC methods are essential for inference in topic models like Latent Dirichlet Allocation:

- **Collapsed Gibbs Sampling**: Integrating out certain variables for efficiency
- **Split-Merge MCMC**: Improving mixing in clustering models

### 4. Bayesian Nonparametrics

Advanced MCMC methods handle the infinite-dimensional nature of nonparametric models:

- **Slice Sampling**: For Dirichlet process mixture models
- **Reversible Jump MCMC**: For models with varying dimensions

### 5. Probabilistic Programming

Modern probabilistic programming languages leverage advanced MCMC methods:

- **Stan**: Uses NUTS as its primary MCMC algorithm
- **PyMC**: Implements HMC, NUTS, and other MCMC methods
- **Edward/TensorFlow Probability**: Provides various MCMC algorithms for deep probabilistic models

## Practical Considerations

### 1. Diagnostics for Advanced MCMC

Standard MCMC diagnostics apply to advanced methods, with some additions:

- **Energy Diagnostics**: For HMC and NUTS, monitoring the Hamiltonian
- **Divergences**: In NUTS, identifying problematic regions of the parameter space
- **Effective Sample Size**: Particularly important for assessing efficiency gains

### 2. Tuning and Adaptation

Many advanced MCMC methods include automatic tuning:

- **NUTS**: Adapts the step size and mass matrix
- **Adaptive Metropolis**: Tunes the proposal covariance
- **Slice Sampling**: Adapts the slice width

### 3. Computational Considerations

Advanced MCMC methods often trade increased per-iteration cost for better mixing:

- **Gradient Computation**: HMC and NUTS require gradient evaluations
- **Parallelization**: Methods like parallel tempering can leverage multiple processors
- **GPU Acceleration**: Gradient-based methods can benefit from GPU computation

## Summary

Advanced MCMC methods address many limitations of basic algorithms, offering improved efficiency and robustness:

1. **Hamiltonian Monte Carlo (HMC)**:
   - Uses gradient information for efficient exploration
   - Reduces random walk behavior
   - Effective for high-dimensional problems

2. **No-U-Turn Sampler (NUTS)**:
   - Extends HMC with adaptive path length
   - Eliminates the need to tune the number of leapfrog steps
   - Widely used in probabilistic programming

3. **Slice Sampling**:
   - Adapts to the local shape of the distribution
   - No need to tune a proposal distribution
   - Works well as a component in Gibbs sampling

4. **Reversible Jump MCMC**:
   - Handles models with varying dimensions
   - Enables Bayesian model selection
   - Useful for changepoint detection and mixture models

5. **Sequential Monte Carlo**:
   - Designed for sequential data
   - Handles non-linear, non-Gaussian state-space models
   - Useful for tracking and filtering

6. **Parallel Tempering**:
   - Improves exploration of multimodal distributions
   - Runs multiple chains at different temperatures
   - Allows exchanges between chains to escape local modes

These advanced methods have enabled the application of Bayesian inference to increasingly complex models in machine learning, from Bayesian neural networks to nonparametric models.

## References

1. Neal, R. M. (2011). MCMC using Hamiltonian dynamics. In Handbook of Markov Chain Monte Carlo (pp. 113-162). CRC Press.
2. Hoffman, M. D., & Gelman, A. (2014). The No-U-Turn Sampler: Adaptively setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593-1623.
3. Neal, R. M. (2003). Slice sampling. Annals of Statistics, 31(3), 705-741.
4. Green, P. J. (1995). Reversible jump Markov chain Monte Carlo computation and Bayesian model determination. Biometrika, 82(4), 711-732.
5. Doucet, A., de Freitas, N., & Gordon, N. (Eds.). (2001). Sequential Monte Carlo Methods in Practice. Springer.
6. Swendsen, R. H., & Wang, J. S. (1986). Replica Monte Carlo simulation of spin glasses. Physical Review Letters, 57(21), 2607-2609.
