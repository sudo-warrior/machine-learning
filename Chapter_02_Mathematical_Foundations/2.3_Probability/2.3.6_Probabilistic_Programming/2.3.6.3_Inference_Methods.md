# 2.3.6.3 Inference Methods in Probabilistic Programming

## Automated Inference in Probabilistic Programming

A key feature of probabilistic programming languages (PPLs) is automated inference—the ability to automatically generate posterior distributions for arbitrary models. This section explores the main inference methods implemented in PPLs, their strengths and limitations, and how they're applied in practice.

## Types of Inference Problems

Before diving into specific algorithms, let's understand the types of inference problems that arise in probabilistic programming:

### 1. Posterior Inference

Computing the posterior distribution p(θ|D) of parameters θ given observed data D:

$$p(\theta|D) = \frac{p(D|\theta)p(\theta)}{p(D)}$$

This is the most common inference task in Bayesian modeling.

### 2. Posterior Predictive Inference

Computing the posterior predictive distribution p(D_new|D) for new data given observed data:

$$p(D_{\text{new}}|D) = \int p(D_{\text{new}}|\theta)p(\theta|D)d\theta$$

This is used for prediction and model checking.

### 3. Marginal Likelihood Estimation

Computing the marginal likelihood (evidence) p(D):

$$p(D) = \int p(D|\theta)p(\theta)d\theta$$

This is used for model comparison and selection.

## Markov Chain Monte Carlo (MCMC) Methods

### Basic Principles

MCMC methods generate samples from the posterior distribution by constructing a Markov chain whose stationary distribution is the target posterior:

$$\theta^{(1)}, \theta^{(2)}, \ldots, \theta^{(N)} \sim p(\theta|D)$$

These samples can then be used to approximate posterior expectations:

$$E[f(\theta)|D] \approx \frac{1}{N}\sum_{i=1}^N f(\theta^{(i)})$$

### Metropolis-Hastings

The **Metropolis-Hastings algorithm** is a general MCMC method that uses a proposal distribution and an acceptance rule:

1. Initialize θ⁰
2. For t = 0, 1, 2, ...:
   a. Propose θ' ~ q(θ'|θᵗ)
   b. Compute acceptance ratio α = min(1, [p(θ'|D)q(θᵗ|θ')]/[p(θᵗ|D)q(θ'|θᵗ)])
   c. With probability α, set θᵗ⁺¹ = θ'; otherwise, set θᵗ⁺¹ = θᵗ

While conceptually simple, Metropolis-Hastings can be inefficient for high-dimensional or complex posteriors.

### Gibbs Sampling

**Gibbs sampling** is a special case of Metropolis-Hastings that samples each parameter conditionally on all others:

1. Initialize θ⁰ = (θ₁⁰, θ₂⁰, ..., θ_d⁰)
2. For t = 0, 1, 2, ...:
   a. Sample θ₁ᵗ⁺¹ ~ p(θ₁|θ₂ᵗ, θ₃ᵗ, ..., θ_dᵗ, D)
   b. Sample θ₂ᵗ⁺¹ ~ p(θ₂|θ₁ᵗ⁺¹, θ₃ᵗ, ..., θ_dᵗ, D)
   c. ...
   d. Sample θ_dᵗ⁺¹ ~ p(θ_d|θ₁ᵗ⁺¹, θ₂ᵗ⁺¹, ..., θ_{d-1}ᵗ⁺¹, D)

Gibbs sampling is efficient when the conditional distributions are easy to sample from, but may struggle with highly correlated parameters.

### Hamiltonian Monte Carlo (HMC)

**Hamiltonian Monte Carlo** uses gradient information to propose more efficient moves:

1. Introduce momentum variables p
2. Define Hamiltonian H(θ, p) = -log p(θ|D) + ½p^T M^{-1} p
3. Simulate Hamiltonian dynamics to propose new states
4. Accept/reject based on the change in Hamiltonian

HMC can explore high-dimensional spaces more efficiently than random-walk methods, but requires gradient computation.

### No-U-Turn Sampler (NUTS)

The **No-U-Turn Sampler** extends HMC by adaptively tuning the path length parameter:

1. Start with a single leapfrog step
2. Recursively double the trajectory until it starts to turn back on itself
3. Sample from the resulting trajectory

NUTS is the default sampler in many modern PPLs like Stan and PyMC due to its efficiency and minimal tuning requirements.

### Example: NUTS in PyMC

```python
import numpy as np
import pymc as pm

# Generate synthetic data
np.random.seed(42)
n = 50
x = np.linspace(0, 10, n)
true_intercept = 1.0
true_slope = 2.0
true_sigma = 1.0
y = true_intercept + true_slope * x + np.random.normal(0, true_sigma, n)

# Define the model
with pm.Model() as linear_model:
    # Priors
    intercept = pm.Normal('intercept', mu=0, sigma=10)
    slope = pm.Normal('slope', mu=0, sigma=10)
    sigma = pm.HalfNormal('sigma', sigma=5)
    
    # Expected value of outcome
    mu = intercept + slope * x
    
    # Likelihood (sampling distribution) of observations
    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)
    
    # Inference with NUTS
    trace = pm.sample(1000, tune=1000)
    
    # Examine the trace
    pm.summary(trace)
```

## Variational Inference Methods

### Basic Principles

**Variational inference** approximates the posterior p(θ|D) with a simpler distribution q(θ) by minimizing the Kullback-Leibler divergence:

$$q^* = \arg\min_q KL(q(\theta) || p(\theta|D))$$

This is equivalent to maximizing the evidence lower bound (ELBO):

$$\text{ELBO}(q) = E_q[\log p(\theta, D)] - E_q[\log q(\theta)]$$

### Mean-Field Variational Inference

**Mean-field variational inference** assumes that the approximate posterior factorizes across parameters:

$$q(\theta) = \prod_{j=1}^d q_j(\theta_j)$$

This simplifies the optimization but may not capture parameter correlations.

### Automatic Differentiation Variational Inference (ADVI)

**ADVI** transforms the constrained parameter space to an unconstrained one and uses automatic differentiation to optimize the ELBO:

1. Transform parameters to unconstrained space: ζ = T(θ)
2. Approximate p(ζ|D) with a Gaussian q(ζ)
3. Optimize the ELBO using stochastic gradient ascent

ADVI is faster than MCMC but provides a less accurate posterior approximation.

### Stochastic Variational Inference (SVI)

**SVI** scales variational inference to large datasets by using stochastic optimization:

1. Subsample data to compute noisy gradients
2. Update variational parameters using stochastic gradient ascent
3. Average over multiple iterations

SVI is particularly useful for large-scale applications.

### Example: ADVI in PyMC

```python
import numpy as np
import pymc as pm

# Using the same model as before
with pm.Model() as linear_model:
    # Priors
    intercept = pm.Normal('intercept', mu=0, sigma=10)
    slope = pm.Normal('slope', mu=0, sigma=10)
    sigma = pm.HalfNormal('sigma', sigma=5)
    
    # Expected value of outcome
    mu = intercept + slope * x
    
    # Likelihood
    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)
    
    # Inference with ADVI
    approx = pm.fit(method='advi', n=30000)
    
    # Sample from the approximate posterior
    trace = approx.sample(1000)
    
    # Examine the trace
    pm.summary(trace)
```

## Sequential Monte Carlo Methods

### Basic Principles

**Sequential Monte Carlo (SMC)** methods, also known as particle filters, approximate the posterior using a set of weighted particles that are updated sequentially:

$$p(\theta|D) \approx \sum_{i=1}^N w_i \delta_{\theta^{(i)}}(\theta)$$

where w_i are importance weights and δ is the Dirac delta function.

### Particle Filtering

**Particle filtering** is used for sequential data, updating the posterior as new observations arrive:

1. Initialize particles θ⁽ⁱ⁾ from the prior
2. For each new observation:
   a. Update weights based on the likelihood
   b. Resample particles according to weights
   c. Propagate particles forward in time

### SMC Samplers

**SMC samplers** extend particle filtering to general (non-sequential) inference problems:

1. Define a sequence of distributions bridging the prior to the posterior
2. Initialize particles from the prior
3. Sequentially update and resample particles through the sequence

SMC can be more robust than MCMC for multimodal posteriors.

### Example: SMC in PyMC

```python
import numpy as np
import pymc as pm

# Using the same model as before
with pm.Model() as linear_model:
    # Priors
    intercept = pm.Normal('intercept', mu=0, sigma=10)
    slope = pm.Normal('slope', mu=0, sigma=10)
    sigma = pm.HalfNormal('sigma', sigma=5)
    
    # Expected value of outcome
    mu = intercept + slope * x
    
    # Likelihood
    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)
    
    # Inference with SMC
    trace = pm.sample_smc(2000)
    
    # Examine the trace
    pm.summary(trace)
```

## Approximate Bayesian Computation (ABC)

### Basic Principles

**Approximate Bayesian Computation** is used when the likelihood is intractable but we can simulate from the model:

1. Sample parameters from the prior: θ⁽ⁱ⁾ ~ p(θ)
2. Simulate data from the model: D⁽ⁱ⁾ ~ p(D|θ⁽ⁱ⁾)
3. Accept θ⁽ⁱ⁾ if D⁽ⁱ⁾ is "close" to the observed data D

### Rejection ABC

The simplest form of ABC is **rejection ABC**:

1. Sample θ⁽ⁱ⁾ ~ p(θ)
2. Simulate D⁽ⁱ⁾ ~ p(D|θ⁽ⁱ⁾)
3. Accept if d(D⁽ⁱ⁾, D) < ε, where d is a distance function and ε is a tolerance

### Sequential ABC

**Sequential ABC** progressively reduces the tolerance:

1. Start with a large tolerance ε₁
2. Run rejection ABC
3. Use the accepted samples to define a new proposal distribution
4. Reduce the tolerance to ε₂ < ε₁ and repeat

### Example: ABC in Python

```python
import numpy as np
import matplotlib.pyplot as plt

# Define a model that we can simulate from
def simulate_data(theta, n_samples):
    """Simulate data from a normal distribution with mean theta and variance 1"""
    return np.random.normal(theta, 1, n_samples)

# Observed data (we pretend we don't know the likelihood)
true_theta = 2.5
observed_data = np.random.normal(true_theta, 1, 20)

# ABC rejection sampling
def abc_rejection(observed_data, n_samples, epsilon):
    accepted_samples = []
    
    while len(accepted_samples) < n_samples:
        # Sample from prior
        theta_candidate = np.random.uniform(-10, 10)  # Uniform prior
        
        # Simulate data
        simulated_data = simulate_data(theta_candidate, len(observed_data))
        
        # Compute summary statistics (here, just the mean)
        observed_mean = np.mean(observed_data)
        simulated_mean = np.mean(simulated_data)
        
        # Accept or reject
        if abs(simulated_mean - observed_mean) < epsilon:
            accepted_samples.append(theta_candidate)
    
    return np.array(accepted_samples)

# Run ABC with different tolerances
epsilons = [1.0, 0.5, 0.2, 0.1]
samples_list = []

for epsilon in epsilons:
    samples = abc_rejection(observed_data, 1000, epsilon)
    samples_list.append(samples)

# Plot the results
plt.figure(figsize=(12, 8))
for i, (epsilon, samples) in enumerate(zip(epsilons, samples_list)):
    plt.subplot(2, 2, i+1)
    plt.hist(samples, bins=30, alpha=0.7)
    plt.axvline(true_theta, color='r', linestyle='--', label='True Value')
    plt.title(f'ε = {epsilon}')
    plt.xlabel('θ')
    plt.ylabel('Frequency')
    plt.legend()

plt.tight_layout()
plt.show()
```

## Inference Diagnostics

### MCMC Diagnostics

Assessing the quality of MCMC inference:

1. **Trace Plots**: Visual inspection of the sample trajectory
   - Look for good mixing and stationarity
   - Identify potential issues like slow mixing or non-convergence

2. **Autocorrelation Plots**: Measuring correlation between samples at different lags
   - High autocorrelation indicates inefficient sampling
   - Compute effective sample size (ESS) to quantify efficiency

3. **Gelman-Rubin Statistic (R-hat)**: Comparing multiple chains
   - R-hat ≈ 1 indicates convergence
   - R-hat > 1.1 suggests non-convergence

4. **Divergences**: In HMC/NUTS, indicating potential issues with the geometry of the posterior
   - Many divergences suggest problems with the model or priors
   - May require reparameterization or stronger priors

### Variational Inference Diagnostics

Assessing the quality of variational inference:

1. **ELBO Convergence**: Monitoring the evidence lower bound
   - Should increase and eventually plateau
   - Sudden drops indicate optimization issues

2. **Comparing with MCMC**: When feasible, compare with MCMC results
   - Check for systematic biases in the approximation
   - Assess whether important posterior features are captured

3. **Predictive Checks**: Evaluating the quality of predictions
   - Compare predictions from VI and MCMC
   - Assess calibration of uncertainty estimates

### Example: MCMC Diagnostics in PyMC

```python
import numpy as np
import pymc as pm
import arviz as az

# Using the same model as before
with pm.Model() as linear_model:
    # Priors
    intercept = pm.Normal('intercept', mu=0, sigma=10)
    slope = pm.Normal('slope', mu=0, sigma=10)
    sigma = pm.HalfNormal('sigma', sigma=5)
    
    # Expected value of outcome
    mu = intercept + slope * x
    
    # Likelihood
    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)
    
    # Inference with multiple chains
    trace = pm.sample(1000, tune=1000, chains=4)
    
    # Examine diagnostics
    summary = az.summary(trace)
    print(summary)
    
    # Trace plots
    az.plot_trace(trace)
    
    # Autocorrelation plots
    az.plot_autocorr(trace)
    
    # Posterior predictive checks
    posterior_predictive = pm.sample_posterior_predictive(trace)
    az.plot_ppc(az.from_pymc(posterior_predictive=posterior_predictive, model=linear_model))
```

## Automatic Inference Selection

### Inference Compilation

Some PPLs automatically select and configure inference algorithms based on the model structure:

```python
# Pseudocode for automatic inference selection
def model(data):
    # Define model here...
    return parameters

# Automatic inference
posterior = infer(model, data)  # System chooses appropriate algorithm
```

### Adaptive Inference

Modern PPLs often include adaptive inference algorithms that tune themselves during execution:

1. **Adaptive MCMC**: Tuning proposal distributions based on acceptance rates
2. **NUTS**: Automatically selecting step sizes and trajectory lengths
3. **Adaptive SMC**: Dynamically adjusting resampling thresholds

### Example: Automatic Inference in Pyro

```python
import torch
import pyro
import pyro.distributions as dist
from pyro.infer import Predictive, NUTS, MCMC, SVI, Trace_ELBO, AutoDiagonalNormal

# Define a simple model
def model(data=None):
    theta = pyro.sample('theta', dist.Normal(0, 10))
    sigma = pyro.sample('sigma', dist.HalfNormal(5))
    
    with pyro.plate('data', len(data) if data is not None else 10):
        return pyro.sample('obs', dist.Normal(theta, sigma), obs=data)

# Generate some data
true_theta = 2.0
data = torch.normal(true_theta, 1.0, (20,))

# Automatic inference with NUTS
nuts_kernel = NUTS(model)
mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=1000)
mcmc.run(data)
posterior_samples = mcmc.get_samples()

# Automatic inference with SVI
guide = AutoDiagonalNormal(model)
svi = SVI(model, guide, pyro.optim.Adam({"lr": 0.01}), loss=Trace_ELBO())

# Run SVI
n_steps = 5000
for step in range(n_steps):
    loss = svi.step(data)
    if step % 500 == 0:
        print(f"Step {step}, Loss: {loss}")

# Get posterior samples from the guide
svi_samples = guide.get_posterior()
```

## Summary

Inference methods in probabilistic programming provide automated tools for computing posterior distributions:

1. **MCMC Methods**:
   - Metropolis-Hastings: General-purpose but potentially inefficient
   - Gibbs Sampling: Efficient for conditionally conjugate models
   - HMC/NUTS: Gradient-based methods for efficient exploration

2. **Variational Inference**:
   - Mean-Field VI: Simple but may miss correlations
   - ADVI: Automatic differentiation for optimization
   - SVI: Scalable to large datasets

3. **Sequential Monte Carlo**:
   - Particle Filtering: For sequential data
   - SMC Samplers: For general inference problems

4. **Approximate Bayesian Computation**:
   - Rejection ABC: Simple but inefficient
   - Sequential ABC: Progressive refinement

5. **Diagnostics and Automation**:
   - MCMC Diagnostics: Trace plots, R-hat, divergences
   - VI Diagnostics: ELBO convergence, comparison with MCMC
   - Automatic Inference: Selection and adaptation of algorithms

These methods enable automated inference for a wide range of probabilistic models, making Bayesian modeling more accessible and practical.

## References

1. Hoffman, M. D., & Gelman, A. (2014). The No-U-Turn Sampler: Adaptively setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593-1623.
2. Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., & Blei, D. M. (2017). Automatic differentiation variational inference. Journal of Machine Learning Research, 18(1), 430-474.
3. Del Moral, P., Doucet, A., & Jasra, A. (2006). Sequential Monte Carlo samplers. Journal of the Royal Statistical Society: Series B, 68(3), 411-436.
4. Sisson, S. A., Fan, Y., & Beaumont, M. (Eds.). (2018). Handbook of approximate Bayesian computation. CRC Press.
5. Betancourt, M. (2018). A conceptual introduction to Hamiltonian Monte Carlo. arXiv preprint arXiv:1701.02434.
