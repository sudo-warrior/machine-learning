# 2.3.8.5 Causal Inference in Machine Learning - Part 2

## Methods for Causal Effect Estimation

Building on the foundations covered in Part 1, this section explores methods for estimating causal effects from observational data. These methods aim to address the challenges of confounding and selection bias that make causal inference difficult.

## Randomized Controlled Trials

**Randomized Controlled Trials (RCTs)** are the gold standard for causal inference:

- **Random assignment** to treatment ensures that treatment groups are comparable
- **Exchangeability** is achieved by design, not by assumption
- **Average Treatment Effect (ATE)** can be estimated by comparing group means

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as stats

# Simulate a randomized controlled trial
np.random.seed(42)
n = 1000

# Covariates (balanced across groups due to randomization)
age = np.random.normal(40, 10, n)
severity = np.random.normal(5, 2, n)

# Random treatment assignment
treatment = np.random.binomial(1, 0.5, n)

# Treatment effect (varies by severity)
effect = 10 - severity

# Potential outcomes
y0 = 70 + 0.1 * age - 2 * severity + np.random.normal(0, 5, n)  # Outcome if not treated
y1 = y0 + effect + np.random.normal(0, 5, n)  # Outcome if treated

# Observed outcome
y_obs = treatment * y1 + (1 - treatment) * y0

# True average treatment effect
true_ate = np.mean(y1 - y0)

# Estimate ATE from RCT
treated_mean = np.mean(y_obs[treatment == 1])
control_mean = np.mean(y_obs[treatment == 0])
estimated_ate = treated_mean - control_mean

# Create a DataFrame
data = pd.DataFrame({
    'Age': age,
    'Severity': severity,
    'Treatment': treatment,
    'Observed Outcome': y_obs,
    'Potential Outcome (T=0)': y0,
    'Potential Outcome (T=1)': y1,
    'Individual Treatment Effect': y1 - y0
})

# Check balance of covariates
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.hist(age[treatment == 1], alpha=0.5, bins=20, label='Treated')
plt.hist(age[treatment == 0], alpha=0.5, bins=20, label='Control')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Distribution of Age by Treatment Group')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.hist(severity[treatment == 1], alpha=0.5, bins=20, label='Treated')
plt.hist(severity[treatment == 0], alpha=0.5, bins=20, label='Control')
plt.xlabel('Severity')
plt.ylabel('Frequency')
plt.title('Distribution of Severity by Treatment Group')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# Plot outcomes by treatment group
plt.figure(figsize=(10, 6))
plt.boxplot([y_obs[treatment == 0], y_obs[treatment == 1]], labels=['Control', 'Treated'])
plt.ylabel('Outcome')
plt.title('Outcome by Treatment Group in RCT')
plt.grid(True)
plt.show()

# Perform t-test
t_stat, p_value = stats.ttest_ind(y_obs[treatment == 1], y_obs[treatment == 0])

# Print results
print(f"True Average Treatment Effect: {true_ate:.2f}")
print(f"Estimated ATE from RCT: {estimated_ate:.2f}")
print(f"T-statistic: {t_stat:.2f}, P-value: {p_value:.4f}")
```

## Matching Methods

**Matching methods** pair treated units with similar control units to adjust for confounding:

- **Exact Matching**: Match on exact values of covariates
- **Propensity Score Matching**: Match on the probability of treatment
- **Nearest Neighbor Matching**: Match based on a distance metric

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import NearestNeighbors

# Generate observational data with confounding
np.random.seed(42)
n = 1000

# Covariates
age = np.random.normal(40, 10, n)
severity = np.random.normal(5, 2, n)

# Treatment assignment (confounded by severity)
propensity = 1 / (1 + np.exp(-(severity - 5)))
treatment = np.random.binomial(1, propensity)

# Treatment effect (varies by severity)
effect = 10 - severity

# Potential outcomes
y0 = 70 + 0.1 * age - 2 * severity + np.random.normal(0, 5, n)  # Outcome if not treated
y1 = y0 + effect + np.random.normal(0, 5, n)  # Outcome if treated

# Observed outcome
y_obs = treatment * y1 + (1 - treatment) * y0

# True average treatment effect
true_ate = np.mean(y1 - y0)

# Naive estimate (ignoring confounding)
treated_mean = np.mean(y_obs[treatment == 1])
control_mean = np.mean(y_obs[treatment == 0])
naive_ate = treated_mean - control_mean

# Create a DataFrame
data = pd.DataFrame({
    'Age': age,
    'Severity': severity,
    'Treatment': treatment,
    'Observed Outcome': y_obs,
    'Propensity': propensity
})

# Estimate propensity scores using logistic regression
X = np.column_stack([age, severity])
propensity_model = LogisticRegression()
propensity_model.fit(X, treatment)
estimated_propensity = propensity_model.predict_proba(X)[:, 1]
data['Estimated Propensity'] = estimated_propensity

# Nearest neighbor matching on propensity score
treated_indices = np.where(treatment == 1)[0]
control_indices = np.where(treatment == 0)[0]

# Fit nearest neighbors model on control units
nn_model = NearestNeighbors(n_neighbors=1)
nn_model.fit(estimated_propensity[control_indices].reshape(-1, 1))

# Find matches for each treated unit
distances, matches = nn_model.kneighbors(estimated_propensity[treated_indices].reshape(-1, 1))
matched_control_indices = control_indices[matches.flatten()]

# Estimate ATE using matched samples
matched_ate = np.mean(y_obs[treated_indices]) - np.mean(y_obs[matched_control_indices])

# Plot propensity score distributions
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.hist(propensity[treatment == 1], alpha=0.5, bins=20, label='Treated')
plt.hist(propensity[treatment == 0], alpha=0.5, bins=20, label='Control')
plt.xlabel('True Propensity Score')
plt.ylabel('Frequency')
plt.title('Distribution of True Propensity Scores')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.hist(estimated_propensity[treatment == 1], alpha=0.5, bins=20, label='Treated')
plt.hist(estimated_propensity[treatment == 0], alpha=0.5, bins=20, label='Control')
plt.xlabel('Estimated Propensity Score')
plt.ylabel('Frequency')
plt.title('Distribution of Estimated Propensity Scores')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# Plot matched pairs
plt.figure(figsize=(10, 6))
plt.scatter(severity[control_indices], y_obs[control_indices], 
           alpha=0.3, label='Control', color='blue')
plt.scatter(severity[treated_indices], y_obs[treated_indices], 
           alpha=0.3, label='Treated', color='orange')
plt.scatter(severity[matched_control_indices], y_obs[matched_control_indices], 
           alpha=0.3, label='Matched Control', color='green', marker='x', s=100)

# Connect matched pairs with lines
for i in range(len(treated_indices)):
    plt.plot([severity[treated_indices[i]], severity[matched_control_indices[i]]], 
             [y_obs[treated_indices[i]], y_obs[matched_control_indices[i]]], 
             'k-', alpha=0.1)

plt.xlabel('Severity')
plt.ylabel('Observed Outcome')
plt.title('Matched Pairs')
plt.legend()
plt.grid(True)
plt.show()

# Print results
print(f"True Average Treatment Effect: {true_ate:.2f}")
print(f"Naive Estimate (Ignoring Confounding): {naive_ate:.2f}")
print(f"Matched Estimate: {matched_ate:.2f}")
```

## Inverse Probability Weighting

**Inverse Probability Weighting (IPW)** reweights observations to create a pseudo-population where treatment is unconfounded:

- **Weights**: 1/P(T|X) for treated units, 1/(1-P(T|X)) for control units
- **Weighted Average**: Estimates the ATE by comparing weighted means

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.linear_model import LogisticRegression

# Use the same observational data from the previous example
# Estimate propensity scores
X = np.column_stack([age, severity])
propensity_model = LogisticRegression()
propensity_model.fit(X, treatment)
estimated_propensity = propensity_model.predict_proba(X)[:, 1]

# Ensure propensity scores are not too close to 0 or 1
estimated_propensity = np.clip(estimated_propensity, 0.01, 0.99)

# Calculate IPW weights
ipw_weights = treatment / estimated_propensity + (1 - treatment) / (1 - estimated_propensity)

# Trim extreme weights
weight_cap = np.percentile(ipw_weights, 99)
ipw_weights = np.minimum(ipw_weights, weight_cap)

# Estimate ATE using IPW
ipw_ate = np.sum(ipw_weights * treatment * y_obs) / np.sum(ipw_weights * treatment) - \
          np.sum(ipw_weights * (1 - treatment) * y_obs) / np.sum(ipw_weights * (1 - treatment))

# Plot weights
plt.figure(figsize=(10, 6))
plt.scatter(estimated_propensity, ipw_weights, alpha=0.5, c=treatment, cmap='viridis')
plt.xlabel('Estimated Propensity Score')
plt.ylabel('IPW Weight')
plt.title('Inverse Probability Weights')
plt.colorbar(label='Treatment')
plt.grid(True)
plt.show()

# Plot weighted outcomes
plt.figure(figsize=(10, 6))
plt.scatter(severity, y_obs, alpha=0.3, c=treatment, cmap='viridis', s=10)
plt.scatter(severity, y_obs, alpha=0.5, c=treatment, cmap='viridis', s=ipw_weights*10)
plt.xlabel('Severity')
plt.ylabel('Observed Outcome')
plt.title('Outcomes with IPW Weights (Larger Points = Higher Weights)')
plt.colorbar(label='Treatment')
plt.grid(True)
plt.show()

# Print results
print(f"True Average Treatment Effect: {true_ate:.2f}")
print(f"Naive Estimate (Ignoring Confounding): {naive_ate:.2f}")
print(f"IPW Estimate: {ipw_ate:.2f}")
```

## Doubly Robust Methods

**Doubly Robust methods** combine outcome modeling and propensity score approaches:

- **Augmented Inverse Probability Weighting (AIPW)**: Combines IPW with outcome regression
- **Double Machine Learning**: Uses cross-fitting to reduce bias from regularization

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.linear_model import LogisticRegression, LinearRegression

# Use the same observational data from the previous examples
# Estimate propensity scores
X = np.column_stack([age, severity])
propensity_model = LogisticRegression()
propensity_model.fit(X, treatment)
estimated_propensity = propensity_model.predict_proba(X)[:, 1]
estimated_propensity = np.clip(estimated_propensity, 0.01, 0.99)

# Fit outcome models for treated and control groups
outcome_model_treated = LinearRegression()
outcome_model_control = LinearRegression()

outcome_model_treated.fit(X[treatment == 1], y_obs[treatment == 1])
outcome_model_control.fit(X[treatment == 0], y_obs[treatment == 0])

# Predict potential outcomes for all units
mu1 = outcome_model_treated.predict(X)
mu0 = outcome_model_control.predict(X)

# Calculate AIPW estimator
aipw_term1 = treatment * (y_obs - mu1) / estimated_propensity
aipw_term2 = (1 - treatment) * (y_obs - mu0) / (1 - estimated_propensity)
aipw_term3 = mu1 - mu0

aipw_ate = np.mean(aipw_term1 - aipw_term2 + aipw_term3)

# Plot predicted potential outcomes
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.scatter(severity, mu1, alpha=0.5, label='E[Y(1)|X]', color='orange')
plt.scatter(severity, mu0, alpha=0.5, label='E[Y(0)|X]', color='blue')
plt.xlabel('Severity')
plt.ylabel('Predicted Potential Outcome')
plt.title('Predicted Potential Outcomes')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.scatter(severity, mu1 - mu0, alpha=0.5, label='CATE', color='green')
plt.axhline(y=aipw_ate, color='red', linestyle='--', label=f'ATE = {aipw_ate:.2f}')
plt.xlabel('Severity')
plt.ylabel('Treatment Effect')
plt.title('Conditional Average Treatment Effect (CATE)')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# Print results
print(f"True Average Treatment Effect: {true_ate:.2f}")
print(f"Naive Estimate (Ignoring Confounding): {naive_ate:.2f}")
print(f"AIPW Estimate: {aipw_ate:.2f}")
```

## Instrumental Variables

**Instrumental Variables (IV)** use a variable that affects the outcome only through its effect on the treatment:

- **Instrument (Z)**: Affects treatment (T) but not directly the outcome (Y)
- **Two-Stage Least Squares (2SLS)**: Common method for IV estimation

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import statsmodels.api as sm

# Generate data with an instrumental variable
np.random.seed(42)
n = 1000

# Instrument (e.g., encouragement to take treatment)
z = np.random.binomial(1, 0.5, n)

# Confounders (observed and unobserved)
observed_confounder = np.random.normal(0, 1, n)
unobserved_confounder = np.random.normal(0, 1, n)

# Treatment (affected by instrument and confounders)
treatment_prob = 1 / (1 + np.exp(-(0.5 * z + 0.5 * observed_confounder + 0.5 * unobserved_confounder)))
treatment = np.random.binomial(1, treatment_prob)

# Outcome (affected by treatment and confounders)
y = 2 * treatment + 0.5 * observed_confounder + 0.5 * unobserved_confounder + np.random.normal(0, 1, n)

# Create a DataFrame
data = pd.DataFrame({
    'Z': z,
    'X': observed_confounder,
    'U': unobserved_confounder,
    'T': treatment,
    'Y': y
})

# Naive OLS estimate (biased due to unobserved confounder)
X_ols = sm.add_constant(np.column_stack([treatment, observed_confounder]))
ols_model = sm.OLS(y, X_ols)
ols_results = ols_model.fit()
ols_estimate = ols_results.params[1]

# First stage: Regress treatment on instrument and observed confounders
X_first = sm.add_constant(np.column_stack([z, observed_confounder]))
first_stage = sm.OLS(treatment, X_first)
first_results = first_stage.fit()
predicted_treatment = first_results.predict()

# Second stage: Regress outcome on predicted treatment and observed confounders
X_second = sm.add_constant(np.column_stack([predicted_treatment, observed_confounder]))
second_stage = sm.OLS(y, X_second)
iv_results = second_stage.fit()
iv_estimate = iv_results.params[1]

# Plot the relationships
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.scatter(z, treatment, alpha=0.3)
plt.xlabel('Instrument (Z)')
plt.ylabel('Treatment (T)')
plt.title('First Stage: Z → T')
plt.grid(True)

plt.subplot(1, 3, 2)
plt.scatter(treatment, y, alpha=0.3)
plt.xlabel('Treatment (T)')
plt.ylabel('Outcome (Y)')
plt.title('Naive Relationship: T → Y')
plt.grid(True)

plt.subplot(1, 3, 3)
plt.scatter(predicted_treatment, y, alpha=0.3)
plt.xlabel('Predicted Treatment')
plt.ylabel('Outcome (Y)')
plt.title('IV Relationship: Predicted T → Y')
plt.grid(True)

plt.tight_layout()
plt.show()

# Print results
print(f"True Treatment Effect: 2.00")
print(f"Naive OLS Estimate: {ols_estimate:.2f}")
print(f"IV Estimate: {iv_estimate:.2f}")
```

## Summary

Methods for causal effect estimation aim to address confounding in observational data:

1. **Randomized Controlled Trials**:
   - Gold standard for causal inference
   - Random assignment ensures exchangeability
   - Allows direct estimation of average treatment effects

2. **Matching Methods**:
   - Pair treated units with similar control units
   - Approaches include exact matching, propensity score matching, and nearest neighbor matching
   - Reduces bias from observed confounders

3. **Inverse Probability Weighting**:
   - Reweights observations to create a pseudo-population
   - Weights based on the inverse of treatment probability
   - Effective when propensity model is correctly specified

4. **Doubly Robust Methods**:
   - Combine outcome modeling and propensity score approaches
   - Consistent if either model is correctly specified
   - Examples include AIPW and double machine learning

5. **Instrumental Variables**:
   - Use a variable that affects treatment but not directly the outcome
   - Useful when unobserved confounders are present
   - Two-stage least squares is a common estimation method

These methods provide a toolkit for estimating causal effects in various scenarios, each with its own assumptions and limitations.

## References

1. Imbens, G. W., & Rubin, D. B. (2015). Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction. Cambridge University Press.
2. Rosenbaum, P. R., & Rubin, D. B. (1983). The central role of the propensity score in observational studies for causal effects. Biometrika, 70(1), 41-55.
3. Robins, J. M., Rotnitzky, A., & Zhao, L. P. (1994). Estimation of regression coefficients when some regressors are not always observed. Journal of the American Statistical Association, 89(427), 846-866.
4. Angrist, J. D., Imbens, G. W., & Rubin, D. B. (1996). Identification of causal effects using instrumental variables. Journal of the American Statistical Association, 91(434), 444-455.
