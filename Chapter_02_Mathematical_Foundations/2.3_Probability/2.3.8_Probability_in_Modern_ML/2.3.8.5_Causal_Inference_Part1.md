# 2.3.8.5 Causal Inference in Machine Learning - Part 1

## Introduction to Causal Inference

Causal inference extends beyond traditional statistical learning by focusing on understanding cause-and-effect relationships rather than just correlations. While machine learning excels at finding patterns in data, causal inference aims to answer "what if" questions and understand the effects of interventions. This section introduces the foundations of causal inference and its importance in machine learning.

## Correlation vs. Causation

### The Fundamental Problem

The phrase "correlation does not imply causation" highlights a fundamental limitation of standard statistical methods:

- **Correlation**: A statistical relationship between variables
- **Causation**: A relationship where one variable directly influences another

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

# Generate synthetic data with spurious correlation
np.random.seed(42)
n = 1000

# Common cause (confounder)
confounder = np.random.normal(0, 1, n)

# Two variables both affected by the confounder
x = confounder + np.random.normal(0, 0.5, n)
y = confounder + np.random.normal(0, 0.5, n)

# Create a DataFrame
data = pd.DataFrame({'X': x, 'Y': y, 'Confounder': confounder})

# Plot the correlation
plt.figure(figsize=(10, 6))
sns.scatterplot(x='X', y='Y', data=data, alpha=0.6)
plt.title(f'Spurious Correlation (r = {np.corrcoef(x, y)[0, 1]:.2f})')
plt.xlabel('Variable X')
plt.ylabel('Variable Y')
plt.grid(True)
plt.show()

# Plot with confounder
plt.figure(figsize=(10, 6))
sns.scatterplot(x='X', y='Y', hue='Confounder', data=data, palette='viridis')
plt.title('Revealing the Common Cause')
plt.xlabel('Variable X')
plt.ylabel('Variable Y')
plt.grid(True)
plt.show()
```

### Simpson's Paradox

**Simpson's Paradox** occurs when a trend appears in different groups of data but disappears or reverses when these groups are combined:

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

# Generate synthetic data for Simpson's Paradox
np.random.seed(42)
n = 1000

# Group variable
group = np.random.binomial(1, 0.5, n)

# X variable (different distribution based on group)
x_group0 = np.random.normal(0, 1, sum(group == 0))
x_group1 = np.random.normal(3, 1, sum(group == 1))
x = np.zeros(n)
x[group == 0] = x_group0
x[group == 1] = x_group1

# Y variable (positive relationship within groups, negative overall)
y = np.zeros(n)
y[group == 0] = 0.5 * x_group0 + np.random.normal(0, 0.5, len(x_group0))
y[group == 1] = 0.5 * x_group1 + np.random.normal(-2, 0.5, len(x_group1))

# Create a DataFrame
data = pd.DataFrame({'X': x, 'Y': y, 'Group': ['A' if g == 0 else 'B' for g in group]})

# Plot the overall relationship
plt.figure(figsize=(15, 5))
plt.subplot(1, 2, 1)
sns.scatterplot(x='X', y='Y', data=data, alpha=0.6)
sns.regplot(x='X', y='Y', data=data, scatter=False, color='red')
plt.title('Overall Relationship (Negative Correlation)')
plt.xlabel('Variable X')
plt.ylabel('Variable Y')
plt.grid(True)

# Plot the relationship by group
plt.subplot(1, 2, 2)
sns.scatterplot(x='X', y='Y', hue='Group', data=data, alpha=0.6)
sns.regplot(x='X', y='Y', data=data[data['Group'] == 'A'], scatter=False, color='blue')
sns.regplot(x='X', y='Y', data=data[data['Group'] == 'B'], scatter=False, color='orange')
plt.title('Relationship by Group (Positive Correlation)')
plt.xlabel('Variable X')
plt.ylabel('Variable Y')
plt.grid(True)

plt.tight_layout()
plt.show()

# Calculate correlations
overall_corr = data['X'].corr(data['Y'])
group_a_corr = data[data['Group'] == 'A']['X'].corr(data[data['Group'] == 'A']['Y'])
group_b_corr = data[data['Group'] == 'B']['X'].corr(data[data['Group'] == 'B']['Y'])

print(f"Overall correlation: {overall_corr:.2f}")
print(f"Group A correlation: {group_a_corr:.2f}")
print(f"Group B correlation: {group_b_corr:.2f}")
```

## Causal Frameworks

### Potential Outcomes Framework

The **Potential Outcomes Framework** (Rubin Causal Model) defines causal effects in terms of potential outcomes:

- Y(1): Outcome if treated
- Y(0): Outcome if not treated
- Causal effect: Y(1) - Y(0)

The fundamental problem of causal inference is that we can only observe one of these potential outcomes for each unit.

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Generate synthetic data for potential outcomes
np.random.seed(42)
n = 1000

# Covariates
age = np.random.normal(40, 10, n)
severity = np.random.normal(5, 2, n)

# Treatment assignment (more likely for severe cases)
propensity = 1 / (1 + np.exp(-(severity - 5)))
treatment = np.random.binomial(1, propensity)

# Potential outcomes
y0 = 70 + 0.1 * age - 2 * severity + np.random.normal(0, 5, n)  # Outcome if not treated
y1 = y0 + 10 - severity + np.random.normal(0, 5, n)  # Outcome if treated

# Observed outcome
y_obs = treatment * y1 + (1 - treatment) * y0

# True treatment effect
true_effect = y1 - y0

# Naive estimate (ignoring confounding)
treated_mean = np.mean(y_obs[treatment == 1])
control_mean = np.mean(y_obs[treatment == 0])
naive_effect = treated_mean - control_mean

# Create a DataFrame
data = pd.DataFrame({
    'Age': age,
    'Severity': severity,
    'Treatment': treatment,
    'Observed Outcome': y_obs,
    'Potential Outcome (T=0)': y0,
    'Potential Outcome (T=1)': y1,
    'Individual Treatment Effect': true_effect
})

# Plot the results
plt.figure(figsize=(15, 5))

# Plot treatment assignment by severity
plt.subplot(1, 3, 1)
plt.scatter(severity, propensity, alpha=0.3)
plt.xlabel('Disease Severity')
plt.ylabel('Probability of Treatment')
plt.title('Treatment Assignment\n(Confounded by Severity)')
plt.grid(True)

# Plot observed outcomes
plt.subplot(1, 3, 2)
plt.scatter(severity[treatment == 1], y_obs[treatment == 1], 
           alpha=0.3, label='Treated', color='orange')
plt.scatter(severity[treatment == 0], y_obs[treatment == 0], 
           alpha=0.3, label='Control', color='blue')
plt.xlabel('Disease Severity')
plt.ylabel('Observed Outcome')
plt.title('Observed Outcomes\nby Treatment Status')
plt.legend()
plt.grid(True)

# Plot potential outcomes
plt.subplot(1, 3, 3)
plt.scatter(severity, y1, alpha=0.3, label='Y(1)', color='orange')
plt.scatter(severity, y0, alpha=0.3, label='Y(0)', color='blue')
plt.xlabel('Disease Severity')
plt.ylabel('Potential Outcomes')
plt.title('Potential Outcomes\n(Usually Unobserved)')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# Print results
print(f"True average treatment effect: {np.mean(true_effect):.2f}")
print(f"Naive estimate (ignoring confounding): {naive_effect:.2f}")
```

### Structural Causal Models

**Structural Causal Models** (SCMs) represent causal relationships using directed graphs and structural equations:

- **Nodes**: Variables in the system
- **Edges**: Direct causal relationships
- **Structural Equations**: Mathematical functions defining how variables are determined

```python
import numpy as np
import matplotlib.pyplot as plt
import networkx as nx

# Define a simple structural causal model
# X -> Y <- Z
# W -> X
# W -> Z

# Generate data from the SCM
np.random.seed(42)
n = 1000

# Exogenous variables
u_w = np.random.normal(0, 1, n)
u_x = np.random.normal(0, 1, n)
u_z = np.random.normal(0, 1, n)
u_y = np.random.normal(0, 1, n)

# Structural equations
w = u_w
x = 0.5 * w + u_x
z = 0.3 * w + u_z
y = 0.7 * x - 0.4 * z + u_y

# Create a directed graph
G = nx.DiGraph()
G.add_nodes_from(['W', 'X', 'Z', 'Y'])
G.add_edges_from([('W', 'X'), ('W', 'Z'), ('X', 'Y'), ('Z', 'Y')])

# Plot the causal graph
plt.figure(figsize=(8, 6))
pos = {'W': (0, 0), 'X': (1, 1), 'Z': (1, -1), 'Y': (2, 0)}
nx.draw(G, pos, with_labels=True, node_size=3000, node_color='lightblue', 
       font_size=15, font_weight='bold', arrowsize=20)
plt.title('Structural Causal Model')
plt.show()

# Plot relationships between variables
plt.figure(figsize=(15, 10))

plt.subplot(2, 3, 1)
plt.scatter(w, x, alpha=0.3)
plt.xlabel('W')
plt.ylabel('X')
plt.title('W → X')
plt.grid(True)

plt.subplot(2, 3, 2)
plt.scatter(w, z, alpha=0.3)
plt.xlabel('W')
plt.ylabel('Z')
plt.title('W → Z')
plt.grid(True)

plt.subplot(2, 3, 3)
plt.scatter(x, y, alpha=0.3)
plt.xlabel('X')
plt.ylabel('Y')
plt.title('X → Y')
plt.grid(True)

plt.subplot(2, 3, 4)
plt.scatter(z, y, alpha=0.3)
plt.xlabel('Z')
plt.ylabel('Y')
plt.title('Z → Y')
plt.grid(True)

plt.subplot(2, 3, 5)
plt.scatter(w, y, alpha=0.3)
plt.xlabel('W')
plt.ylabel('Y')
plt.title('W → Y (Indirect)')
plt.grid(True)

plt.tight_layout()
plt.show()
```

### Do-Calculus

**Do-calculus** provides a formal language for expressing causal interventions and counterfactuals:

- **do(X=x)**: An intervention that sets variable X to value x
- **P(Y|do(X=x))**: The distribution of Y after intervening to set X to x

This differs from the conditional probability P(Y|X=x), which represents observation rather than intervention.

## Causal Assumptions

### Exchangeability (Ignorability)

**Exchangeability** assumes that treatment assignment is independent of potential outcomes given observed covariates:

$$Y(0), Y(1) \perp\!\!\!\perp T | X$$

This is also known as the "no unmeasured confounders" assumption.

### Positivity (Overlap)

**Positivity** requires that every unit has a non-zero probability of receiving each treatment:

$$0 < P(T=1|X=x) < 1 \text{ for all } x \text{ with } P(X=x) > 0$$

### Stable Unit Treatment Value Assumption (SUTVA)

**SUTVA** requires that:
1. No interference: One unit's treatment doesn't affect another unit's outcome
2. No hidden variations of treatments: Each treatment level represents a single, well-defined intervention

## Summary

Causal inference provides a framework for understanding cause-and-effect relationships:

1. **Correlation vs. Causation**:
   - Correlation measures statistical association
   - Causation represents direct influence
   - Simpson's Paradox illustrates how causal relationships can be misleading when analyzed incorrectly

2. **Causal Frameworks**:
   - Potential Outcomes Framework: Defines causal effects as differences between potential outcomes
   - Structural Causal Models: Represent causal relationships using directed graphs and equations
   - Do-Calculus: Provides a formal language for expressing interventions

3. **Causal Assumptions**:
   - Exchangeability: No unmeasured confounders
   - Positivity: All units have a chance of receiving each treatment
   - SUTVA: No interference between units and no hidden treatment variations

In Part 2, we will explore methods for estimating causal effects from observational data.

## References

1. Pearl, J. (2009). Causality: Models, Reasoning, and Inference (2nd ed.). Cambridge University Press.
2. Rubin, D. B. (1974). Estimating causal effects of treatments in randomized and nonrandomized studies. Journal of Educational Psychology, 66(5), 688-701.
3. Imbens, G. W., & Rubin, D. B. (2015). Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction. Cambridge University Press.
4. Hernán, M. A., & Robins, J. M. (2020). Causal Inference: What If. Chapman & Hall/CRC.
