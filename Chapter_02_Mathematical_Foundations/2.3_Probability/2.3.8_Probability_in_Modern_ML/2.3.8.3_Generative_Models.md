# 2.3.8.3 Generative Models

## Introduction to Generative Models

Generative models are a class of machine learning models that learn to generate new data samples that resemble their training data. Unlike discriminative models that learn the boundary between classes, generative models capture the underlying data distribution, enabling them to create new, synthetic examples. This section explores the probabilistic foundations and applications of modern generative models.

## Probabilistic Foundations

### Generative vs. Discriminative Models

From a probabilistic perspective:

- **Discriminative Models** learn the conditional probability p(y|x) - the probability of a label y given input x
- **Generative Models** learn the joint probability p(x,y) or just p(x) - the probability distribution over the data

Generative models can be used to:
1. Generate new samples by drawing from the learned distribution
2. Compute the likelihood of observed data
3. Perform inference on missing data through conditional sampling

## Basic Generative Models

### Gaussian Mixture Models

**Gaussian Mixture Models** (GMMs) represent the data distribution as a weighted sum of Gaussian distributions:

$$p(x) = \sum_{k=1}^K \pi_k \mathcal{N}(x | \mu_k, \Sigma_k)$$

where:
- $\pi_k$ are the mixture weights (summing to 1)
- $\mu_k$ and $\Sigma_k$ are the mean and covariance of each Gaussian component

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.mixture import GaussianMixture
from sklearn.datasets import make_blobs

# Generate synthetic data
np.random.seed(42)
X, y = make_blobs(n_samples=1000, centers=3, cluster_std=[1.0, 2.0, 0.5], random_state=42)

# Fit a Gaussian Mixture Model
gmm = GaussianMixture(n_components=3, covariance_type='full', random_state=42)
gmm.fit(X)

# Generate new samples
X_new, y_new = gmm.sample(500)

# Plot the results
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', alpha=0.5)
plt.title('Original Data')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')

plt.subplot(1, 2, 2)
plt.scatter(X_new[:, 0], X_new[:, 1], c=y_new, cmap='viridis', alpha=0.5)
plt.title('Generated Samples')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')

plt.tight_layout()
plt.show()

# Visualize the learned distribution
x = np.linspace(-10, 10, 100)
y = np.linspace(-10, 10, 100)
X_grid, Y_grid = np.meshgrid(x, y)
XX = np.array([X_grid.ravel(), Y_grid.ravel()]).T

# Compute log-likelihood for each point in the grid
Z = -gmm.score_samples(XX)
Z = Z.reshape(X_grid.shape)

plt.figure(figsize=(10, 8))
plt.contourf(X_grid, Y_grid, Z, levels=50, cmap='viridis', alpha=0.7)
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolors='w', alpha=0.5)
plt.colorbar(label='Negative Log-Likelihood')
plt.title('GMM Density Estimation')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.tight_layout()
plt.show()
```

### Hidden Markov Models

**Hidden Markov Models** (HMMs) are generative models for sequential data with hidden states:

- **Hidden States**: A Markov chain of latent variables z₁, z₂, ..., zₙ
- **Observations**: Each state emits an observation x₁, x₂, ..., xₙ
- **Parameters**: Transition probabilities p(zₜ|zₜ₋₁) and emission probabilities p(xₜ|zₜ)

```python
import numpy as np
from hmmlearn import hmm
import matplotlib.pyplot as plt

# Define an HMM model
model = hmm.GaussianHMM(n_components=3, covariance_type="full", random_state=42)

# Set the transition matrix
model.startprob_ = np.array([0.6, 0.3, 0.1])
model.transmat_ = np.array([
    [0.7, 0.2, 0.1],
    [0.3, 0.5, 0.2],
    [0.2, 0.2, 0.6]
])

# Set the means and covariances of the output distributions
model.means_ = np.array([
    [0.0, 0.0],
    [3.0, -3.0],
    [-3.0, 3.0]
])
model.covars_ = np.tile(np.identity(2), (3, 1, 1))

# Generate samples
X, Z = model.sample(500)

# Plot the results
plt.figure(figsize=(10, 8))
plt.scatter(X[:, 0], X[:, 1], c=Z, cmap='viridis', alpha=0.8, edgecolors='w')
plt.colorbar(label='Hidden State')
plt.title('Samples from Hidden Markov Model')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.grid(True)
plt.show()

# Plot the sequence of states
plt.figure(figsize=(12, 4))
plt.plot(Z, '-o', markersize=4, alpha=0.7)
plt.xlabel('Time Step')
plt.ylabel('Hidden State')
plt.title('Sequence of Hidden States')
plt.grid(True)
plt.show()
```

## Deep Generative Models

### Variational Autoencoders (VAEs)

**Variational Autoencoders** combine neural networks with variational inference to learn complex data distributions:

- **Encoder Network**: Approximates the posterior q(z|x) of latent variables
- **Decoder Network**: Defines the likelihood p(x|z)
- **Training Objective**: Evidence Lower Bound (ELBO)

$$ELBO = E_{q(z|x)}[\log p(x|z)] - D_{KL}(q(z|x) || p(z))$$

```python
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Lambda, Reshape, Conv2D, Conv2DTranspose, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras import backend as K
from tensorflow.keras.datasets import mnist
import numpy as np
import matplotlib.pyplot as plt

# Load and preprocess MNIST data
(x_train, _), (x_test, _) = mnist.load_data()
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)

# Network parameters
input_shape = (28, 28, 1)
batch_size = 128
latent_dim = 2

# Define encoder
inputs = Input(shape=input_shape)
x = Conv2D(32, 3, strides=2, padding='same', activation='relu')(inputs)
x = Conv2D(64, 3, strides=2, padding='same', activation='relu')(x)
x = Flatten()(x)
x = Dense(16, activation='relu')(x)

z_mean = Dense(latent_dim)(x)
z_log_var = Dense(latent_dim)(x)

# Sampling function
def sampling(args):
    z_mean, z_log_var = args
    batch = K.shape(z_mean)[0]
    dim = K.int_shape(z_mean)[1]
    epsilon = K.random_normal(shape=(batch, dim))
    return z_mean + K.exp(0.5 * z_log_var) * epsilon

z = Lambda(sampling)([z_mean, z_log_var])

# Define decoder
decoder_input = Input(shape=(latent_dim,))
x = Dense(7 * 7 * 64, activation='relu')(decoder_input)
x = Reshape((7, 7, 64))(x)
x = Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu')(x)
x = Conv2DTranspose(32, 3, strides=2, padding='same', activation='relu')(x)
outputs = Conv2DTranspose(1, 3, padding='same', activation='sigmoid')(x)

# Define models
encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')
decoder = Model(decoder_input, outputs, name='decoder')
outputs = decoder(encoder(inputs)[2])
vae = Model(inputs, outputs, name='vae')

# Define loss
reconstruction_loss = tf.reduce_mean(
    tf.reduce_sum(
        tf.keras.losses.binary_crossentropy(inputs, outputs),
        axis=(1, 2)
    )
)
kl_loss = -0.5 * tf.reduce_mean(
    tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)
)
vae_loss = reconstruction_loss + kl_loss

vae.add_loss(vae_loss)
vae.compile(optimizer='adam')

# Train the model
vae.fit(x_train, epochs=10, batch_size=batch_size, validation_data=(x_test, None))

# Display a 2D manifold of the digits
n = 15  # figure with 15x15 digits
digit_size = 28
figure = np.zeros((digit_size * n, digit_size * n))

# Linearly spaced coordinates on the unit square were transformed
# through the inverse CDF (ppf) of the Gaussian to produce values
# of the latent variables z, since the prior of the latent space
# is Gaussian
grid_x = np.linspace(-3, 3, n)
grid_y = np.linspace(-3, 3, n)[::-1]

for i, yi in enumerate(grid_y):
    for j, xi in enumerate(grid_x):
        z_sample = np.array([[xi, yi]])
        x_decoded = decoder.predict(z_sample)
        digit = x_decoded[0].reshape(digit_size, digit_size)
        figure[i * digit_size: (i + 1) * digit_size,
               j * digit_size: (j + 1) * digit_size] = digit

plt.figure(figsize=(10, 10))
plt.imshow(figure, cmap='Greys_r')
plt.title('VAE Generated Digits')
plt.axis('off')
plt.show()
```

### Generative Adversarial Networks (GANs)

**Generative Adversarial Networks** use a game-theoretic approach with two competing networks:

- **Generator**: Creates synthetic samples to fool the discriminator
- **Discriminator**: Distinguishes between real and generated samples
- **Training Objective**: Minimax game between generator and discriminator

$$\min_G \max_D V(D, G) = E_{x \sim p_{data}}[\log D(x)] + E_{z \sim p_z}[\log(1 - D(G(z)))]$$

```python
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout
from tensorflow.keras.layers import BatchNormalization, LeakyReLU
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.optimizers import Adam
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist

# Load and preprocess MNIST data
(x_train, _), (_, _) = mnist.load_data()
x_train = x_train.astype('float32') / 255.
x_train = np.expand_dims(x_train, -1)

# Network parameters
img_rows = 28
img_cols = 28
channels = 1
img_shape = (img_rows, img_cols, channels)
latent_dim = 100

# Build the generator
def build_generator():
    model = Sequential()
    
    model.add(Dense(128 * 7 * 7, activation="relu", input_dim=latent_dim))
    model.add(Reshape((7, 7, 128)))
    model.add(BatchNormalization(momentum=0.8))
    model.add(tf.keras.layers.UpSampling2D())
    model.add(tf.keras.layers.Conv2D(128, kernel_size=3, padding="same"))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(tf.keras.layers.UpSampling2D())
    model.add(tf.keras.layers.Conv2D(64, kernel_size=3, padding="same"))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(tf.keras.layers.Conv2D(channels, kernel_size=3, padding="same", activation="sigmoid"))
    
    noise = Input(shape=(latent_dim,))
    img = model(noise)
    
    return Model(noise, img)

# Build the discriminator
def build_discriminator():
    model = Sequential()
    
    model.add(tf.keras.layers.Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding="same"))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.25))
    model.add(tf.keras.layers.Conv2D(64, kernel_size=3, strides=2, padding="same"))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.25))
    model.add(tf.keras.layers.Conv2D(128, kernel_size=3, strides=2, padding="same"))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.25))
    model.add(Flatten())
    model.add(Dense(1, activation="sigmoid"))
    
    img = Input(shape=img_shape)
    validity = model(img)
    
    return Model(img, validity)

# Build and compile the discriminator
discriminator = build_discriminator()
discriminator.compile(loss='binary_crossentropy',
                      optimizer=Adam(0.0002, 0.5),
                      metrics=['accuracy'])

# Build the generator
generator = build_generator()

# The generator takes noise as input and generates imgs
z = Input(shape=(latent_dim,))
img = generator(z)

# For the combined model we will only train the generator
discriminator.trainable = False

# The discriminator takes generated images as input and determines validity
validity = discriminator(img)

# The combined model (stacked generator and discriminator)
# Trains the generator to fool the discriminator
combined = Model(z, validity)
combined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))

# Training parameters
batch_size = 32
epochs = 10000
sample_interval = 1000

# Training the GAN
def train_gan(epochs, batch_size, sample_interval):
    # Adversarial ground truths
    valid = np.ones((batch_size, 1))
    fake = np.zeros((batch_size, 1))
    
    for epoch in range(epochs):
        # Train Discriminator
        idx = np.random.randint(0, x_train.shape[0], batch_size)
        imgs = x_train[idx]
        
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        gen_imgs = generator.predict(noise)
        
        d_loss_real = discriminator.train_on_batch(imgs, valid)
        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
        
        # Train Generator
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        g_loss = combined.train_on_batch(noise, valid)
        
        # Print progress
        if epoch % 100 == 0:
            print(f"Epoch {epoch}, D Loss: {d_loss[0]}, G Loss: {g_loss}")
        
        # Save generated images
        if epoch % sample_interval == 0:
            sample_images(epoch)

# Function to save generated images
def sample_images(epoch):
    r, c = 5, 5
    noise = np.random.normal(0, 1, (r * c, latent_dim))
    gen_imgs = generator.predict(noise)
    
    # Rescale images 0 - 1
    gen_imgs = 0.5 * gen_imgs + 0.5
    
    fig, axs = plt.subplots(r, c)
    cnt = 0
    for i in range(r):
        for j in range(c):
            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')
            axs[i,j].axis('off')
            cnt += 1
    fig.savefig(f"gan_images/mnist_{epoch}.png")
    plt.close()

# Create a directory for generated images
import os
os.makedirs("gan_images", exist_ok=True)

# Train for a few epochs for demonstration
train_gan(epochs=5, batch_size=batch_size, sample_interval=1)

# Generate and display some images
noise = np.random.normal(0, 1, (25, latent_dim))
gen_imgs = generator.predict(noise)

plt.figure(figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i+1)
    plt.imshow(gen_imgs[i, :, :, 0], cmap='gray')
    plt.axis('off')
plt.tight_layout()
plt.show()
```

### Normalizing Flows

**Normalizing Flows** transform a simple base distribution into a complex target distribution through a sequence of invertible transformations:

$$p(x) = p(z) \left| \det \frac{\partial f^{-1}}{\partial x} \right|$$

where $z = f^{-1}(x)$ and $f$ is an invertible function.

Key properties:
- Exact likelihood computation
- Efficient sampling
- Invertible transformations

## Applications of Generative Models

### Data Augmentation

Generative models can create synthetic training examples to improve model performance:

```python
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Reshape, Flatten
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt

# Load and preprocess Fashion MNIST data
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))
x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))
y_train_cat = to_categorical(y_train)
y_test_cat = to_categorical(y_test)

# Define a simple classifier
def build_classifier():
    model = Sequential()
    model.add(Flatten(input_shape=(28, 28, 1)))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(10, activation='softmax'))
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Train with original data
classifier_original = build_classifier()
classifier_original.fit(x_train, y_train_cat, batch_size=128, epochs=5, validation_data=(x_test, y_test_cat))

# Evaluate
score_original = classifier_original.evaluate(x_test, y_test_cat, verbose=0)
print(f"Original Test Accuracy: {score_original[1]:.4f}")

# Simple data augmentation
datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1
)
datagen.fit(x_train)

# Train with augmented data
classifier_augmented = build_classifier()
classifier_augmented.fit(datagen.flow(x_train, y_train_cat, batch_size=128),
                        steps_per_epoch=len(x_train) // 128,
                        epochs=5,
                        validation_data=(x_test, y_test_cat))

# Evaluate
score_augmented = classifier_augmented.evaluate(x_test, y_test_cat, verbose=0)
print(f"Augmented Test Accuracy: {score_augmented[1]:.4f}")

# Visualize some augmented images
plt.figure(figsize=(10, 10))
for i, (x_batch, y_batch) in enumerate(datagen.flow(x_train, y_train, batch_size=25)):
    for j in range(25):
        plt.subplot(5, 5, j+1)
        plt.imshow(x_batch[j].reshape(28, 28), cmap='gray')
        plt.axis('off')
    plt.tight_layout()
    plt.show()
    break
```

### Anomaly Detection

Generative models can identify anomalies by assigning low likelihood to unusual samples:

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.mixture import GaussianMixture

# Generate normal data
X_normal, _ = make_blobs(n_samples=1000, centers=3, cluster_std=[1.0, 1.5, 0.5], random_state=42)

# Generate anomalies
X_anomalies = np.random.uniform(low=-10, high=10, size=(50, 2))

# Combine data (without labels for training)
X_combined = np.vstack([X_normal, X_anomalies])

# Fit a GMM to the data
gmm = GaussianMixture(n_components=3, covariance_type='full', random_state=42)
gmm.fit(X_normal)  # Train only on normal data

# Compute log-likelihood for all points
log_probs_normal = gmm.score_samples(X_normal)
log_probs_anomalies = gmm.score_samples(X_anomalies)

# Set a threshold for anomaly detection
threshold = np.percentile(log_probs_normal, 1)  # Bottom 1% as threshold

# Classify points as normal or anomalous
y_pred_normal = log_probs_normal > threshold
y_pred_anomalies = log_probs_anomalies > threshold

# Calculate accuracy
accuracy_normal = np.mean(y_pred_normal)
accuracy_anomalies = np.mean(~y_pred_anomalies)
print(f"Normal data correctly classified: {accuracy_normal:.4f}")
print(f"Anomalies correctly classified: {accuracy_anomalies:.4f}")

# Visualize the results
plt.figure(figsize=(12, 10))

# Create a grid for density visualization
x_min, x_max = X_combined[:, 0].min() - 1, X_combined[:, 0].max() + 1
y_min, y_max = X_combined[:, 1].min() - 1, X_combined[:, 1].max() + 1
xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))
Z = -gmm.score_samples(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# Plot the density and points
plt.contourf(xx, yy, Z, levels=50, cmap='viridis', alpha=0.5)
plt.scatter(X_normal[:, 0], X_normal[:, 1], c='blue', alpha=0.5, label='Normal')
plt.scatter(X_anomalies[:, 0], X_anomalies[:, 1], c='red', marker='x', alpha=0.8, label='Anomalies')

# Plot the decision boundary
plt.contour(xx, yy, Z, levels=[threshold], colors='red', linestyles='dashed')

plt.colorbar(label='Negative Log-Likelihood')
plt.title('Anomaly Detection with GMM')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.grid(True)
plt.show()
```

### Image-to-Image Translation

Generative models can transform images from one domain to another:

- **Pix2Pix**: Conditional GANs for paired image translation
- **CycleGAN**: Unpaired image translation with cycle consistency
- **StyleGAN**: High-quality image generation with style control

### Text Generation

Generative models can create coherent text:

- **Language Models**: Predicting the next token in a sequence
- **Conditional Text Generation**: Generating text based on prompts
- **Text-to-Text Transformations**: Translation, summarization, paraphrasing

## Evaluation of Generative Models

### Likelihood-Based Evaluation

For models with tractable likelihoods:

- **Log-likelihood**: Higher values indicate better fit
- **Perplexity**: Common in language modeling
- **Bits-per-dimension**: Normalized log-likelihood for images

### Sample-Based Evaluation

For models without tractable likelihoods:

- **Inception Score (IS)**: Measures quality and diversity
- **Fréchet Inception Distance (FID)**: Compares feature distributions
- **Precision and Recall**: Evaluates fidelity and coverage

```python
# Pseudocode for computing FID
def compute_fid(real_images, generated_images):
    # Extract features using a pre-trained model (e.g., Inception)
    real_features = extract_features(real_images)
    gen_features = extract_features(generated_images)
    
    # Compute mean and covariance for both feature sets
    mu_real, sigma_real = compute_statistics(real_features)
    mu_gen, sigma_gen = compute_statistics(gen_features)
    
    # Compute FID
    fid = compute_distance_between_gaussians(
        [mu_real, sigma_real], [mu_gen, sigma_gen]
    )
    
    return fid
```

### Human Evaluation

Subjective assessment remains important:

- **Visual Turing Tests**: Can humans distinguish real from generated?
- **Preference Studies**: Which model produces better outputs?
- **Task-Specific Evaluation**: How well do generated samples perform in downstream tasks?

## Challenges and Future Directions

### Mode Collapse

Generative models, especially GANs, can suffer from mode collapse:

- **Problem**: Generator produces limited variety of samples
- **Solutions**: Minibatch discrimination, unrolled GANs, diversity-promoting objectives

### Training Stability

Training generative models can be unstable:

- **GANs**: Balancing generator and discriminator training
- **VAEs**: Balancing reconstruction and KL terms
- **Flows**: Numerical stability in computing determinants

### Scalability

Scaling generative models to high-resolution or complex data:

- **Progressive Growing**: Incrementally increasing resolution
- **Hierarchical Models**: Modeling at multiple scales
- **Efficient Architectures**: Reducing computational requirements

## Summary

Generative models provide powerful tools for modeling complex data distributions:

1. **Basic Generative Models**:
   - Gaussian Mixture Models: Weighted sum of Gaussians
   - Hidden Markov Models: Sequential data with hidden states

2. **Deep Generative Models**:
   - Variational Autoencoders: Neural networks with variational inference
   - Generative Adversarial Networks: Adversarial training of generator and discriminator
   - Normalizing Flows: Invertible transformations of simple distributions

3. **Applications**:
   - Data Augmentation: Creating synthetic training examples
   - Anomaly Detection: Identifying unusual samples
   - Image-to-Image Translation: Transforming images between domains
   - Text Generation: Creating coherent text

4. **Evaluation Methods**:
   - Likelihood-Based: Log-likelihood, perplexity
   - Sample-Based: Inception Score, FID
   - Human Evaluation: Visual Turing tests, preference studies

5. **Challenges**:
   - Mode Collapse: Limited variety in generated samples
   - Training Stability: Balancing competing objectives
   - Scalability: Handling high-dimensional data

Generative models continue to advance rapidly, enabling increasingly realistic and diverse synthetic data generation across various domains.

## References

1. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial nets. Advances in Neural Information Processing Systems, 27.
2. Kingma, D. P., & Welling, M. (2013). Auto-encoding variational Bayes. arXiv preprint arXiv:1312.6114.
3. Rezende, D. J., & Mohamed, S. (2015). Variational inference with normalizing flows. arXiv preprint arXiv:1505.05770.
4. Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., & Hochreiter, S. (2017). GANs trained by a two time-scale update rule converge to a local Nash equilibrium. Advances in Neural Information Processing Systems, 30.
