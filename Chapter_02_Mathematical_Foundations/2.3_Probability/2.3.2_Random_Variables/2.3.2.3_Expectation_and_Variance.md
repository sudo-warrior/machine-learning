# 2.3.2.3 Expectation and Variance

## Understanding Expectation and Variance

Expectation and variance are fundamental concepts in probability theory and statistics that provide essential information about random variables. These measures help us understand the central tendency and dispersion of probability distributions, which are crucial for analyzing data and building machine learning models. In this section, we'll explore expectation, variance, and related concepts in depth, along with their applications in machine learning.

## Expectation (Expected Value)

### Definition

The **expectation** or **expected value** of a random variable X, denoted as E[X] or μ, represents the long-run average value of the random variable over many independent repetitions of an experiment.

For a **discrete random variable** with probability mass function p(x):

$$E[X] = \sum_x x \cdot p(x)$$

For a **continuous random variable** with probability density function f(x):

$$E[X] = \int_{-\infty}^{\infty} x \cdot f(x) dx$$

### Interpretation

The expectation can be interpreted in several ways:

1. **Long-run Average**: The average value we would observe if we repeated the random experiment infinitely many times
2. **Center of Mass**: The point where the probability distribution would balance if it were a physical object
3. **First Moment**: The first moment of the probability distribution about the origin

### Properties of Expectation

1. **Linearity**: For random variables X and Y, and constants a and b:
   $$E[aX + bY] = aE[X] + bE[Y]$$
   This property holds even if X and Y are not independent.

2. **Expectation of a Constant**: For any constant c:
   $$E[c] = c$$

3. **Expectation of a Function**: For a function g(X):
   $$E[g(X)] = \sum_x g(x) \cdot p(x)$$ (discrete case)
   $$E[g(X)] = \int_{-\infty}^{\infty} g(x) \cdot f(x) dx$$ (continuous case)

4. **Law of the Unconscious Statistician**: We can compute E[g(X)] directly without first finding the distribution of g(X).

5. **Expectation of a Product**: If X and Y are independent:
   $$E[XY] = E[X] \cdot E[Y]$$
   If X and Y are not independent, this property does not generally hold.

### Examples of Expectation

#### Discrete Example: Dice Roll

For a fair six-sided die:
- E[X] = (1 + 2 + 3 + 4 + 5 + 6) / 6 = 21 / 6 = 3.5

#### Continuous Example: Standard Normal Distribution

For a standard normal distribution (μ = 0, σ = 1):
- E[X] = 0

#### Example: Expected Value of a Function

If X is a fair dice roll and g(X) = X²:
- E[X²] = (1² + 2² + 3² + 4² + 5² + 6²) / 6 = 91 / 6 ≈ 15.17

## Variance and Standard Deviation

### Definition of Variance

The **variance** of a random variable X, denoted as Var(X) or σ², measures the spread or dispersion of the distribution around the mean:

$$\text{Var}(X) = E[(X - E[X])^2]$$

For a **discrete random variable**:

$$\text{Var}(X) = \sum_x (x - E[X])^2 \cdot p(x)$$

For a **continuous random variable**:

$$\text{Var}(X) = \int_{-\infty}^{\infty} (x - E[X])^2 \cdot f(x) dx$$

### Alternative Formula for Variance

An alternative formula for computing variance is:

$$\text{Var}(X) = E[X^2] - (E[X])^2$$

This formula is often more convenient for calculations.

### Definition of Standard Deviation

The **standard deviation** of X, denoted as σ or SD(X), is the square root of the variance:

$$\sigma = \sqrt{\text{Var}(X)}$$

The standard deviation has the same units as the random variable, making it more interpretable than variance.

### Properties of Variance

1. **Non-negativity**: Var(X) ≥ 0 for any random variable X
2. **Variance of a Constant**: Var(c) = 0 for any constant c
3. **Scaling**: Var(aX) = a² · Var(X) for any constant a
4. **Variance of a Sum**: If X and Y are independent:
   $$\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y)$$
5. **General Formula for Variance of a Sum**:
   $$\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y) + 2\text{Cov}(X, Y)$$
   where Cov(X, Y) is the covariance between X and Y.

### Examples of Variance and Standard Deviation

#### Discrete Example: Dice Roll

For a fair six-sided die:
- E[X] = 3.5
- E[X²] = 15.17
- Var(X) = E[X²] - (E[X])² = 15.17 - 3.5² = 15.17 - 12.25 = 2.92
- σ = √2.92 ≈ 1.71

#### Continuous Example: Standard Normal Distribution

For a standard normal distribution (μ = 0, σ = 1):
- Var(X) = 1 (by definition)
- σ = 1

#### Example: Variance of a Function

If X is a fair dice roll and g(X) = 2X + 3:
- E[g(X)] = E[2X + 3] = 2E[X] + 3 = 2(3.5) + 3 = 10
- Var(g(X)) = Var(2X + 3) = 2² · Var(X) = 4 · 2.92 = 11.68
- σ_g(X) = √11.68 ≈ 3.42

## Higher Moments and Other Measures

### Moments

The **k-th moment** of a random variable X about the origin is defined as:

$$E[X^k]$$

The **k-th central moment** of X is defined as:

$$E[(X - E[X])^k]$$

Note that the variance is the second central moment.

### Skewness

**Skewness** measures the asymmetry of a probability distribution. It is the third standardized moment:

$$\text{Skewness} = \frac{E[(X - E[X])^3]}{(\text{Var}(X))^{3/2}}$$

- Positive skewness indicates a distribution with a longer right tail
- Negative skewness indicates a distribution with a longer left tail
- Zero skewness (like the normal distribution) indicates symmetry

### Kurtosis

**Kurtosis** measures the "tailedness" of a probability distribution. It is the fourth standardized moment:

$$\text{Kurtosis} = \frac{E[(X - E[X])^4]}{(\text{Var}(X))^2}$$

- Higher kurtosis indicates heavier tails and a sharper peak
- Lower kurtosis indicates lighter tails and a flatter peak
- The normal distribution has a kurtosis of 3

**Excess kurtosis** is defined as kurtosis minus 3, so the normal distribution has an excess kurtosis of 0.

### Median and Mode

The **median** of a random variable X is a value m such that:
- P(X ≤ m) ≥ 0.5 and P(X ≥ m) ≥ 0.5

The **mode** of a discrete random variable is the value that occurs with the highest probability. For a continuous random variable, it's the value where the PDF reaches its maximum.

Unlike the mean, the median and mode are not affected by extreme values, making them robust measures of central tendency.

## Covariance and Correlation

### Covariance

The **covariance** between two random variables X and Y, denoted as Cov(X, Y), measures how they vary together:

$$\text{Cov}(X, Y) = E[(X - E[X])(Y - E[Y])]$$

An alternative formula is:

$$\text{Cov}(X, Y) = E[XY] - E[X]E[Y]$$

Properties of covariance:
1. Cov(X, X) = Var(X)
2. Cov(X, Y) = Cov(Y, X)
3. Cov(aX, bY) = ab · Cov(X, Y) for constants a and b
4. Cov(X + Z, Y) = Cov(X, Y) + Cov(Z, Y)
5. If X and Y are independent, then Cov(X, Y) = 0 (but the converse is not necessarily true)

### Correlation Coefficient

The **correlation coefficient** between X and Y, denoted as ρ(X, Y) or Corr(X, Y), normalizes the covariance:

$$\rho(X, Y) = \frac{\text{Cov}(X, Y)}{\sqrt{\text{Var}(X) \cdot \text{Var}(Y)}}$$

Properties of correlation:
1. -1 ≤ ρ(X, Y) ≤ 1
2. ρ(X, Y) = 1 implies perfect positive linear relationship
3. ρ(X, Y) = -1 implies perfect negative linear relationship
4. ρ(X, Y) = 0 implies no linear relationship (but possibly a non-linear relationship)
5. ρ(aX + b, cY + d) = ρ(X, Y) if a·c > 0, and ρ(aX + b, cY + d) = -ρ(X, Y) if a·c < 0

## Conditional Expectation and Variance

### Conditional Expectation

The **conditional expectation** of X given Y = y, denoted as E[X|Y = y], is the expected value of X under the conditional distribution of X given Y = y:

For discrete random variables:

$$E[X|Y = y] = \sum_x x \cdot p(x|y)$$

For continuous random variables:

$$E[X|Y = y] = \int_{-\infty}^{\infty} x \cdot f(x|y) dx$$

### Law of Total Expectation

The **law of total expectation** (or law of iterated expectation) states:

$$E[X] = E[E[X|Y]]$$

That is, the expected value of X equals the expected value of the conditional expectation of X given Y.

### Conditional Variance

The **conditional variance** of X given Y = y, denoted as Var(X|Y = y), is:

$$\text{Var}(X|Y = y) = E[(X - E[X|Y = y])^2|Y = y]$$

### Law of Total Variance

The **law of total variance** states:

$$\text{Var}(X) = E[\text{Var}(X|Y)] + \text{Var}(E[X|Y])$$

This decomposes the total variance into:
1. The expected value of the conditional variance (within-group variance)
2. The variance of the conditional expectation (between-group variance)

## Expectation and Variance in Machine Learning

### 1. Loss Functions and Risk Minimization

In machine learning, we often minimize the expected loss (risk):

$$R(h) = E[L(h(X), Y)]$$

where h is a hypothesis, L is a loss function, and the expectation is over the joint distribution of X and Y.

Common loss functions include:
- **Mean Squared Error**: L(h(x), y) = (h(x) - y)²
- **Cross-Entropy Loss**: L(h(x), y) = -y log(h(x)) - (1-y) log(1-h(x))

### 2. Bias-Variance Decomposition

The expected test error of a model can be decomposed into:

$$E[(h(X) - Y)^2] = \text{Bias}(h)^2 + \text{Variance}(h) + \text{Irreducible Error}$$

where:
- **Bias**: The error from incorrect assumptions in the learning algorithm
- **Variance**: The error from sensitivity to small fluctuations in the training set
- **Irreducible Error**: The noise in the true relationship

### 3. Regularization

Regularization techniques like L1 and L2 regularization can be viewed as adding a penalty to the variance of the model parameters:

$$L_{\text{regularized}} = L_{\text{original}} + \lambda \cdot \text{Penalty}(\theta)$$

where θ represents the model parameters and λ controls the strength of regularization.

### 4. Ensemble Methods

Ensemble methods like bagging reduce variance by averaging multiple models:

$$h_{\text{ensemble}}(x) = \frac{1}{m} \sum_{i=1}^m h_i(x)$$

If the individual models have variance σ² and are uncorrelated, the ensemble variance is σ²/m.

### 5. Bayesian Machine Learning

In Bayesian machine learning, we work with the posterior distribution of parameters:

$$p(\theta|D) \propto p(D|\theta) \cdot p(\theta)$$

The posterior mean E[θ|D] provides a point estimate, while the posterior variance Var(θ|D) quantifies uncertainty.

### 6. Reinforcement Learning

In reinforcement learning, the value function is defined as the expected sum of future rewards:

$$V^\pi(s) = E\left[ \sum_{t=0}^{\infty} \gamma^t R_{t+1} \bigg| S_0 = s, \pi \right]$$

where γ is the discount factor, R_t is the reward at time t, and π is the policy.

## Estimation of Expectation and Variance

### Sample Mean

The **sample mean** is an estimator of the population mean:

$$\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i$$

Properties:
- Unbiased: E[X̄] = E[X]
- Variance: Var(X̄) = Var(X)/n
- Consistency: X̄ converges to E[X] as n → ∞

### Sample Variance

The **sample variance** is an estimator of the population variance:

$$S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})^2$$

The factor 1/(n-1) (rather than 1/n) makes the estimator unbiased.

Properties:
- Unbiased: E[S²] = Var(X)
- Consistency: S² converges to Var(X) as n → ∞

### Monte Carlo Estimation

For complex expectations, **Monte Carlo methods** approximate E[g(X)] by sampling:

$$E[g(X)] \approx \frac{1}{n} \sum_{i=1}^n g(X_i)$$

where X₁, X₂, ..., X_n are independent samples from the distribution of X.

## Visualizing Expectation and Variance

### Probability Distributions with Different Means

```
  f(x)
   │
   │    ╱╲      ╱╲      ╱╲
   │   ╱  ╲    ╱  ╲    ╱  ╲
   │  ╱    ╲  ╱    ╲  ╱    ╲
   │ ╱      ╲╱      ╲╱      ╲
   └─────────────────────────── x
      μ₁     μ₂     μ₃
```

### Probability Distributions with Different Variances

```
  f(x)
   │
   │      ╱╲
   │     ╱  ╲
   │    ╱    ╲
   │   ╱ ╱╲   ╲
   │  ╱ ╱  ╲   ╲
   │ ╱ ╱    ╲   ╲
   │╱╱      ╲╲   ╲
   └─────────────────── x
        μ
   
   Small variance: Narrow, tall peak
   Large variance: Wide, short peak
```

### Correlation Visualization

```
  y
  │       ρ ≈ 1           ρ ≈ 0           ρ ≈ -1
  │       ╱               ·  · ·           ╲
  │     ·╱              · ·  ·  ·           ╲·
  │    ·╱               ·· · ·               ╲·
  │   ·╱              · · ·· ·                ╲·
  │  ·╱                · · · ·                 ╲·
  │ ·╱                ·  ·· ·                  ╲·
  │·╱                 · ·  ·                    ╲·
  └─────────────────────────────────────────────── x
```

## Practical Considerations

### 1. Numerical Stability

When computing variance using the formula Var(X) = E[X²] - (E[X])², numerical instability can occur if E[X] is large. Alternative formulations like:

$$\text{Var}(X) = \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})^2$$

can be more stable.

### 2. Handling Outliers

Expectation and variance are sensitive to outliers. Robust alternatives include:
- **Median** instead of mean
- **Interquartile range (IQR)** or **median absolute deviation (MAD)** instead of variance

### 3. Estimating Expectations in High Dimensions

In high-dimensional spaces, estimating expectations can be challenging due to the curse of dimensionality. Techniques to address this include:
- Importance sampling
- Markov Chain Monte Carlo (MCMC)
- Variational methods

### 4. Expectations of Complex Functions

For complex functions without closed-form expectations, approaches include:
- Numerical integration
- Monte Carlo sampling
- Taylor series approximations

## Summary

Expectation and variance are fundamental concepts in probability theory and machine learning:

1. **Expectation (E[X])** represents the long-run average or center of mass of a random variable's distribution.
   - Linear: E[aX + bY] = aE[X] + bE[Y]
   - For independent X and Y: E[XY] = E[X]E[Y]

2. **Variance (Var(X))** measures the spread or dispersion around the mean.
   - Always non-negative
   - For independent X and Y: Var(X + Y) = Var(X) + Var(Y)
   - Scaling: Var(aX) = a²Var(X)

3. **Standard Deviation (σ)** is the square root of variance, providing a measure of spread in the same units as the random variable.

4. **Covariance and Correlation** measure the relationship between random variables.
   - Covariance: Cov(X, Y) = E[(X - E[X])(Y - E[Y])]
   - Correlation: ρ(X, Y) = Cov(X, Y) / (σ_X · σ_Y)

5. **Conditional Expectation and Variance** provide insights into how one random variable behaves given information about another.
   - Law of Total Expectation: E[X] = E[E[X|Y]]
   - Law of Total Variance: Var(X) = E[Var(X|Y)] + Var(E[X|Y])

These concepts are essential in machine learning for:
- Formulating loss functions and risk minimization
- Understanding bias-variance tradeoffs
- Implementing regularization techniques
- Developing ensemble methods
- Quantifying uncertainty in Bayesian approaches
- Defining value functions in reinforcement learning

By mastering expectation and variance, machine learning practitioners can better understand model behavior, quantify uncertainty, and make more informed decisions.

## References

1. Wasserman, L. (2004). All of Statistics: A Concise Course in Statistical Inference. Springer.
2. Murphy, K. P. (2012). Machine Learning: A Probabilistic Perspective. MIT Press.
3. Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.
4. Hastie, T., Tibshirani, R., & Friedman, J. (2009). The Elements of Statistical Learning (2nd ed.). Springer.
