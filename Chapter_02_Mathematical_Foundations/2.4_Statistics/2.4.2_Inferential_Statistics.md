# 2.4.2 Inferential Statistics

## Introduction to Inferential Statistics

Inferential statistics allows us to draw conclusions about populations based on sample data. While descriptive statistics summarize what's in our data, inferential statistics help us make predictions and test hypotheses about the broader population. This section covers the fundamental concepts of inferential statistics that are essential for machine learning.

## Sampling and Distributions

### Population vs. Sample

- **Population**: The entire group we want to draw conclusions about
- **Sample**: A subset of the population that we actually observe
- **Parameter**: A numerical characteristic of a population (e.g., μ, σ)
- **Statistic**: A numerical characteristic of a sample (e.g., x̄, s)

### Sampling Distributions

A **sampling distribution** is the distribution of a statistic calculated from repeated samples of the same size from a population.

#### Sampling Distribution of the Mean

The Central Limit Theorem (CLT) states that the sampling distribution of the mean approaches a normal distribution as the sample size increases, regardless of the population distribution.

- Mean of the sampling distribution: μx̄ = μ
- Standard error of the mean: σx̄ = σ/√n

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Demonstrate the Central Limit Theorem
np.random.seed(42)

# Create a non-normal population (exponential distribution)
population = np.random.exponential(scale=1.0, size=10000)

# Take samples of different sizes and calculate means
sample_sizes = [1, 5, 10, 30, 100]
num_samples = 1000
sample_means = {}

for size in sample_sizes:
    means = []
    for _ in range(num_samples):
        sample = np.random.choice(population, size=size)
        means.append(np.mean(sample))
    sample_means[size] = means

# Plot the results
plt.figure(figsize=(15, 10))

# Plot the population distribution
plt.subplot(2, 3, 1)
plt.hist(population, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
plt.title('Population Distribution\n(Exponential)')
plt.xlabel('Value')
plt.ylabel('Frequency')
plt.grid(True, alpha=0.3)

# Plot the sampling distributions for different sample sizes
for i, size in enumerate(sample_sizes):
    plt.subplot(2, 3, i+2)
    plt.hist(sample_means[size], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
    plt.title(f'Sampling Distribution\nSample Size = {size}')
    plt.xlabel('Sample Mean')
    plt.ylabel('Frequency')
    plt.grid(True, alpha=0.3)
    
    # Add normal curve for comparison
    x = np.linspace(min(sample_means[size]), max(sample_means[size]), 100)
    y = stats.norm.pdf(x, np.mean(sample_means[size]), np.std(sample_means[size]))
    plt.plot(x, y * len(sample_means[size]) * (max(sample_means[size]) - min(sample_means[size])) / 30, 
             'r-', linewidth=2)

plt.tight_layout()
plt.show()
```

## Confidence Intervals

A **confidence interval** provides a range of values that likely contains the population parameter.

### Confidence Interval for the Mean

For a 95% confidence interval for the population mean:

$$\bar{x} \pm 1.96 \times \frac{s}{\sqrt{n}}$$

where:
- x̄ is the sample mean
- s is the sample standard deviation
- n is the sample size
- 1.96 is the z-score for 95% confidence (assuming a normal distribution)

For small samples (n < 30), we use the t-distribution instead of the normal distribution.

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Generate sample data
np.random.seed(42)
sample = np.random.normal(loc=50, scale=10, size=30)

# Calculate 95% confidence interval
sample_mean = np.mean(sample)
sample_std = np.std(sample, ddof=1)
n = len(sample)

# Using t-distribution for small sample
t_critical = stats.t.ppf(0.975, df=n-1)  # 95% confidence (two-tailed)
margin_of_error = t_critical * (sample_std / np.sqrt(n))
confidence_interval = (sample_mean - margin_of_error, sample_mean + margin_of_error)

# Plot the sample and confidence interval
plt.figure(figsize=(10, 6))
plt.hist(sample, bins=10, alpha=0.7, color='skyblue', edgecolor='black')
plt.axvline(sample_mean, color='red', linestyle='dashed', linewidth=2, label=f'Sample Mean: {sample_mean:.2f}')
plt.axvline(confidence_interval[0], color='green', linestyle='dashed', linewidth=2, 
           label=f'95% CI: ({confidence_interval[0]:.2f}, {confidence_interval[1]:.2f})')
plt.axvline(confidence_interval[1], color='green', linestyle='dashed', linewidth=2)
plt.title('Sample Distribution with 95% Confidence Interval')
plt.xlabel('Value')
plt.ylabel('Frequency')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

# Demonstrate confidence interval interpretation
# Generate multiple samples and calculate CIs
num_samples = 100
sample_size = 30
population_mean = 50

contains_mean = 0
confidence_intervals = []

for _ in range(num_samples):
    sample = np.random.normal(loc=population_mean, scale=10, size=sample_size)
    sample_mean = np.mean(sample)
    sample_std = np.std(sample, ddof=1)
    margin_of_error = t_critical * (sample_std / np.sqrt(sample_size))
    ci_lower = sample_mean - margin_of_error
    ci_upper = sample_mean + margin_of_error
    confidence_intervals.append((ci_lower, ci_upper))
    
    if ci_lower <= population_mean <= ci_upper:
        contains_mean += 1

# Plot multiple confidence intervals
plt.figure(figsize=(12, 8))
for i, (lower, upper) in enumerate(confidence_intervals):
    color = 'blue' if lower <= population_mean <= upper else 'red'
    plt.plot([lower, upper], [i, i], color=color, linewidth=2)
    plt.plot(lower, i, color=color, marker='|', markersize=10)
    plt.plot(upper, i, color=color, marker='|', markersize=10)

plt.axvline(population_mean, color='green', linestyle='dashed', linewidth=2, 
           label=f'Population Mean: {population_mean}')
plt.title(f'95% Confidence Intervals from {num_samples} Samples\n'
          f'{contains_mean}% contain the true population mean')
plt.xlabel('Value')
plt.ylabel('Sample Number')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

## Hypothesis Testing

**Hypothesis testing** is a method for making decisions about populations based on sample data.

### Null and Alternative Hypotheses

- **Null Hypothesis (H₀)**: A statement of no effect or no difference
- **Alternative Hypothesis (H₁ or Hₐ)**: A statement of an effect or a difference

### p-values and Significance Levels

- **p-value**: The probability of obtaining results at least as extreme as the observed results, assuming the null hypothesis is true
- **Significance Level (α)**: The threshold below which we reject the null hypothesis (commonly 0.05)

### Types of Errors

- **Type I Error**: Rejecting a true null hypothesis (false positive)
- **Type II Error**: Failing to reject a false null hypothesis (false negative)

### One-Sample t-test

Tests whether a sample mean differs from a specified population mean.

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Generate sample data
np.random.seed(42)
sample = np.random.normal(loc=52, scale=10, size=30)  # Sample with mean slightly higher than 50

# Perform one-sample t-test
hypothesized_mean = 50
t_stat, p_value = stats.ttest_1samp(sample, hypothesized_mean)

# Print results
print(f"Sample Mean: {np.mean(sample):.2f}")
print(f"Hypothesized Mean: {hypothesized_mean}")
print(f"t-statistic: {t_stat:.4f}")
print(f"p-value: {p_value:.4f}")
print(f"Conclusion: {'Reject' if p_value < 0.05 else 'Fail to reject'} the null hypothesis at α = 0.05")

# Visualize the t-distribution and test statistic
df = len(sample) - 1  # Degrees of freedom
x = np.linspace(-4, 4, 1000)
y = stats.t.pdf(x, df)

# Critical values for two-tailed test at α = 0.05
critical_value = stats.t.ppf(0.975, df)

plt.figure(figsize=(10, 6))
plt.plot(x, y, 'b-', linewidth=2, label='t-distribution')
plt.fill_between(x[x <= -critical_value], y[x <= -critical_value], color='red', alpha=0.3, label='Rejection region')
plt.fill_between(x[x >= critical_value], y[x >= critical_value], color='red', alpha=0.3)
plt.axvline(t_stat, color='green', linestyle='dashed', linewidth=2, label=f't-statistic: {t_stat:.4f}')
plt.axvline(critical_value, color='red', linestyle='dashed', linewidth=1, label=f'Critical value: ±{critical_value:.4f}')
plt.axvline(-critical_value, color='red', linestyle='dashed', linewidth=1)
plt.title('One-Sample t-Test')
plt.xlabel('t-value')
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

### Two-Sample t-test

Tests whether the means of two independent samples differ.

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Generate two sample groups
np.random.seed(42)
group1 = np.random.normal(loc=50, scale=10, size=30)
group2 = np.random.normal(loc=55, scale=10, size=30)  # Slightly higher mean

# Perform two-sample t-test
t_stat, p_value = stats.ttest_ind(group1, group2)

# Print results
print(f"Group 1 Mean: {np.mean(group1):.2f}")
print(f"Group 2 Mean: {np.mean(group2):.2f}")
print(f"Difference: {np.mean(group2) - np.mean(group1):.2f}")
print(f"t-statistic: {t_stat:.4f}")
print(f"p-value: {p_value:.4f}")
print(f"Conclusion: {'Reject' if p_value < 0.05 else 'Fail to reject'} the null hypothesis at α = 0.05")

# Visualize the groups
plt.figure(figsize=(10, 6))
plt.hist(group1, bins=10, alpha=0.5, color='blue', label=f'Group 1 (Mean: {np.mean(group1):.2f})')
plt.hist(group2, bins=10, alpha=0.5, color='red', label=f'Group 2 (Mean: {np.mean(group2):.2f})')
plt.axvline(np.mean(group1), color='blue', linestyle='dashed', linewidth=2)
plt.axvline(np.mean(group2), color='red', linestyle='dashed', linewidth=2)
plt.title('Two-Sample t-Test')
plt.xlabel('Value')
plt.ylabel('Frequency')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

## Statistical Power and Sample Size

**Statistical power** is the probability of correctly rejecting a false null hypothesis.

Factors affecting statistical power:
1. Sample size (n)
2. Effect size
3. Significance level (α)
4. Variability in the data

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Demonstrate the effect of sample size on statistical power
np.random.seed(42)

# Parameters
effect_sizes = [0.2, 0.5, 0.8]  # Small, medium, large effect sizes
sample_sizes = np.arange(10, 100, 5)
alpha = 0.05
num_simulations = 1000

# Calculate power for different effect sizes and sample sizes
power_results = np.zeros((len(effect_sizes), len(sample_sizes)))

for i, effect_size in enumerate(effect_sizes):
    for j, n in enumerate(sample_sizes):
        # Run simulations
        significant_tests = 0
        
        for _ in range(num_simulations):
            # Generate data with the specified effect size
            group1 = np.random.normal(loc=0, scale=1, size=n)
            group2 = np.random.normal(loc=effect_size, scale=1, size=n)
            
            # Perform t-test
            _, p_value = stats.ttest_ind(group1, group2)
            
            # Count significant results
            if p_value < alpha:
                significant_tests += 1
        
        # Calculate power
        power_results[i, j] = significant_tests / num_simulations

# Plot the results
plt.figure(figsize=(10, 6))
for i, effect_size in enumerate(effect_sizes):
    plt.plot(sample_sizes, power_results[i], marker='o', label=f'Effect Size = {effect_size}')

plt.axhline(0.8, color='red', linestyle='dashed', linewidth=2, label='Target Power = 0.8')
plt.title('Statistical Power vs. Sample Size')
plt.xlabel('Sample Size')
plt.ylabel('Power (1 - β)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

## Effect Size

**Effect size** measures the magnitude of a phenomenon, independent of sample size.

Common effect size measures:
- **Cohen's d**: Standardized mean difference
- **Correlation coefficient (r)**: Relationship between variables
- **Odds ratio**: Ratio of odds of an event occurring in one group to the odds in another group

```python
import numpy as np
from scipy import stats

# Calculate Cohen's d for two groups
def cohens_d(group1, group2):
    # Pooled standard deviation
    n1, n2 = len(group1), len(group2)
    s1, s2 = np.std(group1, ddof=1), np.std(group2, ddof=1)
    s_pooled = np.sqrt(((n1 - 1) * s1**2 + (n2 - 1) * s2**2) / (n1 + n2 - 2))
    
    # Effect size
    d = (np.mean(group1) - np.mean(group2)) / s_pooled
    return d

# Generate two sample groups
np.random.seed(42)
group1 = np.random.normal(loc=50, scale=10, size=30)
group2 = np.random.normal(loc=55, scale=10, size=30)

# Calculate effect size
d = cohens_d(group1, group2)
print(f"Cohen's d: {d:.4f}")

# Interpret effect size
if abs(d) < 0.2:
    interpretation = "negligible"
elif abs(d) < 0.5:
    interpretation = "small"
elif abs(d) < 0.8:
    interpretation = "medium"
else:
    interpretation = "large"

print(f"Interpretation: {interpretation} effect size")
```

## Inferential Statistics in Machine Learning

### Cross-Validation

**Cross-validation** estimates how well a model will generalize to an independent dataset.

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.datasets import make_regression

# Generate synthetic data
np.random.seed(42)
X, y = make_regression(n_samples=100, n_features=1, noise=20, random_state=42)

# Perform k-fold cross-validation
model = LinearRegression()
cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')
cv_rmse = np.sqrt(-cv_scores)

# Print results
print(f"Cross-validation RMSE scores: {cv_rmse}")
print(f"Mean RMSE: {np.mean(cv_rmse):.4f}")
print(f"Standard deviation of RMSE: {np.std(cv_rmse):.4f}")
print(f"95% CI for RMSE: ({np.mean(cv_rmse) - 1.96 * np.std(cv_rmse) / np.sqrt(5):.4f}, "
      f"{np.mean(cv_rmse) + 1.96 * np.std(cv_rmse) / np.sqrt(5):.4f})")

# Plot the data and regression line
plt.figure(figsize=(10, 6))
plt.scatter(X, y, alpha=0.7, color='blue')

# Fit the model on the entire dataset for visualization
model.fit(X, y)
x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
y_pred = model.predict(x_range)
plt.plot(x_range, y_pred, color='red', linewidth=2)

plt.title('Linear Regression with Cross-Validation')
plt.xlabel('X')
plt.ylabel('y')
plt.grid(True, alpha=0.3)
plt.show()
```

### Bootstrap

**Bootstrap** resamples the data with replacement to estimate the sampling distribution of a statistic.

```python
import numpy as np
import matplotlib.pyplot as plt

# Generate sample data
np.random.seed(42)
sample = np.random.normal(loc=50, scale=10, size=30)

# Perform bootstrap to estimate the sampling distribution of the mean
n_bootstrap = 1000
bootstrap_means = []

for _ in range(n_bootstrap):
    # Resample with replacement
    bootstrap_sample = np.random.choice(sample, size=len(sample), replace=True)
    bootstrap_means.append(np.mean(bootstrap_sample))

# Calculate bootstrap confidence interval
bootstrap_ci = np.percentile(bootstrap_means, [2.5, 97.5])

# Plot the bootstrap distribution
plt.figure(figsize=(10, 6))
plt.hist(bootstrap_means, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
plt.axvline(np.mean(sample), color='red', linestyle='dashed', linewidth=2, 
           label=f'Sample Mean: {np.mean(sample):.2f}')
plt.axvline(bootstrap_ci[0], color='green', linestyle='dashed', linewidth=2, 
           label=f'95% Bootstrap CI: ({bootstrap_ci[0]:.2f}, {bootstrap_ci[1]:.2f})')
plt.axvline(bootstrap_ci[1], color='green', linestyle='dashed', linewidth=2)
plt.title('Bootstrap Distribution of the Mean')
plt.xlabel('Sample Mean')
plt.ylabel('Frequency')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

### A/B Testing

**A/B testing** compares two versions of a model or system to determine which performs better.

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Simulate A/B test data for click-through rates
np.random.seed(42)
n_A = 1000  # Number of users in group A
n_B = 1000  # Number of users in group B
p_A = 0.10  # True click-through rate for group A
p_B = 0.12  # True click-through rate for group B

# Generate data
clicks_A = np.random.binomial(1, p_A, n_A)
clicks_B = np.random.binomial(1, p_B, n_B)

# Calculate observed click-through rates
ctr_A = np.mean(clicks_A)
ctr_B = np.mean(clicks_B)

# Perform statistical test (two-proportion z-test)
count_A = np.sum(clicks_A)
count_B = np.sum(clicks_B)
p_pooled = (count_A + count_B) / (n_A + n_B)
z_stat = (ctr_B - ctr_A) / np.sqrt(p_pooled * (1 - p_pooled) * (1/n_A + 1/n_B))
p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))  # Two-tailed test

# Print results
print(f"Group A: {count_A} clicks out of {n_A} users (CTR: {ctr_A:.4f})")
print(f"Group B: {count_B} clicks out of {n_B} users (CTR: {ctr_B:.4f})")
print(f"Absolute difference: {ctr_B - ctr_A:.4f}")
print(f"Relative difference: {(ctr_B - ctr_A) / ctr_A:.4f} ({(ctr_B - ctr_A) / ctr_A * 100:.2f}%)")
print(f"z-statistic: {z_stat:.4f}")
print(f"p-value: {p_value:.4f}")
print(f"Conclusion: {'Statistically significant' if p_value < 0.05 else 'Not statistically significant'} at α = 0.05")

# Visualize the results
plt.figure(figsize=(10, 6))
plt.bar(['Group A', 'Group B'], [ctr_A, ctr_B], color=['blue', 'green'], alpha=0.7)
plt.title('A/B Test Results: Click-Through Rate Comparison')
plt.ylabel('Click-Through Rate')
plt.grid(True, alpha=0.3, axis='y')

# Add error bars (95% confidence intervals)
ci_A = 1.96 * np.sqrt(ctr_A * (1 - ctr_A) / n_A)
ci_B = 1.96 * np.sqrt(ctr_B * (1 - ctr_B) / n_B)
plt.errorbar(['Group A', 'Group B'], [ctr_A, ctr_B], yerr=[ci_A, ci_B], fmt='o', color='black', 
            capsize=10, label='95% Confidence Interval')

plt.legend()
plt.show()
```

## Summary

Inferential statistics provides tools to draw conclusions about populations based on sample data:

1. **Sampling and Distributions**:
   - Population vs. Sample
   - Sampling Distribution
   - Central Limit Theorem

2. **Confidence Intervals**:
   - Quantify uncertainty in parameter estimates
   - Wider intervals indicate less precision

3. **Hypothesis Testing**:
   - Null and Alternative Hypotheses
   - p-values and Significance Levels
   - Type I and Type II Errors
   - t-tests for comparing means

4. **Statistical Power and Sample Size**:
   - Power increases with sample size and effect size
   - Power decreases with variability

5. **Effect Size**:
   - Measures the magnitude of a phenomenon
   - Cohen's d, correlation coefficient, odds ratio

6. **Applications in Machine Learning**:
   - Cross-Validation
   - Bootstrap
   - A/B Testing

Inferential statistics forms the foundation for making data-driven decisions and evaluating machine learning models.

## References

1. Wasserman, L. (2013). All of Statistics: A Concise Course in Statistical Inference. Springer.
2. Hogg, R. V., McKean, J. W., & Craig, A. T. (2018). Introduction to Mathematical Statistics (8th ed.). Pearson.
3. James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An Introduction to Statistical Learning. Springer.
4. Efron, B., & Tibshirani, R. J. (1994). An Introduction to the Bootstrap. CRC Press.
