# 2.2.3.2 Chain Rule for Multivariate Functions

## Introduction

In machine learning, we often work with functions of multiple variables. The Chain Rule for multivariate functions extends the basic Chain Rule to handle these more complex scenarios. This is particularly important for understanding gradient descent in multiple dimensions and backpropagation in neural networks.

## Chain Rule for Functions of Multiple Variables

### Case 1: Composite Function with Multiple Inputs

Consider a function f(x, y) composed with functions x = g(t) and y = h(t), resulting in a single-variable function F(t) = f(g(t), h(t)).

The derivative of F with respect to t is:

$$\frac{dF}{dt} = \frac{\partial f}{\partial x} \cdot \frac{dg}{dt} + \frac{\partial f}{\partial y} \cdot \frac{dh}{dt}$$

This is the dot product of the gradient of f and the vector of derivatives of the inner functions.

### Case 2: Composite Function with Multiple Intermediate Variables

Consider a function f(u, v) where u = g(x, y) and v = h(x, y), resulting in a function F(x, y) = f(g(x, y), h(x, y)).

The partial derivatives of F are:

$$\frac{\partial F}{\partial x} = \frac{\partial f}{\partial u} \cdot \frac{\partial g}{\partial x} + \frac{\partial f}{\partial v} \cdot \frac{\partial h}{\partial x}$$

$$\frac{\partial F}{\partial y} = \frac{\partial f}{\partial u} \cdot \frac{\partial g}{\partial y} + \frac{\partial f}{\partial v} \cdot \frac{\partial h}{\partial y}$$

### General Form: The Jacobian Matrix

For a vector-valued function F = f(g(x)), where:
- x is a vector of input variables (x₁, x₂, ..., xₙ)
- g is a vector-valued function (g₁, g₂, ..., gₘ)
- f is a vector-valued function (f₁, f₂, ..., fₚ)

The Jacobian matrix of F with respect to x is:

$$\frac{\partial F}{\partial x} = \frac{\partial f}{\partial g} \cdot \frac{\partial g}{\partial x}$$

where · represents matrix multiplication, and the Jacobian matrices are:

$$\frac{\partial f}{\partial g} = \begin{bmatrix} 
\frac{\partial f_1}{\partial g_1} & \frac{\partial f_1}{\partial g_2} & \cdots & \frac{\partial f_1}{\partial g_m} \\
\frac{\partial f_2}{\partial g_1} & \frac{\partial f_2}{\partial g_2} & \cdots & \frac{\partial f_2}{\partial g_m} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial f_p}{\partial g_1} & \frac{\partial f_p}{\partial g_2} & \cdots & \frac{\partial f_p}{\partial g_m}
\end{bmatrix}$$

$$\frac{\partial g}{\partial x} = \begin{bmatrix} 
\frac{\partial g_1}{\partial x_1} & \frac{\partial g_1}{\partial x_2} & \cdots & \frac{\partial g_1}{\partial x_n} \\
\frac{\partial g_2}{\partial x_1} & \frac{\partial g_2}{\partial x_2} & \cdots & \frac{\partial g_2}{\partial x_n} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial g_m}{\partial x_1} & \frac{\partial g_m}{\partial x_2} & \cdots & \frac{\partial g_m}{\partial x_n}
\end{bmatrix}$$

## Examples of Multivariate Chain Rule

### Example 1: F(t) = f(x(t), y(t)) = x(t)² + y(t)²

Let x(t) = cos(t) and y(t) = sin(t).

1. Compute ∂f/∂x = 2x and ∂f/∂y = 2y
2. Compute dx/dt = -sin(t) and dy/dt = cos(t)
3. Apply the Chain Rule: dF/dt = (∂f/∂x)(dx/dt) + (∂f/∂y)(dy/dt) = 2x(-sin(t)) + 2y(cos(t)) = -2cos(t)sin(t) + 2sin(t)cos(t) = 0

This makes sense because F(t) = cos²(t) + sin²(t) = 1, which is constant, so its derivative is 0.

```python
import numpy as np
import matplotlib.pyplot as plt
import sympy as sp

# Define the functions
def x(t):
    return np.cos(t)

def y(t):
    return np.sin(t)

def f(x, y):
    return x**2 + y**2

def F(t):
    return f(x(t), y(t))

# Compute the derivatives
def df_dx(x, y):
    return 2*x

def df_dy(x, y):
    return 2*y

def dx_dt(t):
    return -np.sin(t)

def dy_dt(t):
    return np.cos(t)

def dF_dt(t):
    return df_dx(x(t), y(t)) * dx_dt(t) + df_dy(x(t), y(t)) * dy_dt(t)

# Verify with symbolic differentiation
t_sym = sp.Symbol('t')
x_sym = sp.cos(t_sym)
y_sym = sp.sin(t_sym)
f_sym = x_sym**2 + y_sym**2
F_sym = f_sym.subs([(sp.Symbol('x'), x_sym), (sp.Symbol('y'), y_sym)])
dF_sym = sp.diff(F_sym, t_sym)

print(f"F(t) = {F_sym}")
print(f"dF/dt = {dF_sym}")

# Plot the functions
t_vals = np.linspace(0, 2*np.pi, 1000)
x_vals = x(t_vals)
y_vals = y(t_vals)
F_vals = F(t_vals)
dF_vals = dF_dt(t_vals)

plt.figure(figsize=(15, 10))

# Plot the parametric curve (x(t), y(t))
plt.subplot(2, 2, 1)
plt.plot(x_vals, y_vals, 'b-')
plt.grid(True)
plt.axis('equal')
plt.xlabel('x(t) = cos(t)')
plt.ylabel('y(t) = sin(t)')
plt.title('Parametric Curve: (cos(t), sin(t))')

# Plot F(t) = x(t)² + y(t)²
plt.subplot(2, 2, 2)
plt.plot(t_vals, F_vals, 'g-')
plt.grid(True)
plt.xlabel('t')
plt.ylabel('F(t)')
plt.title('F(t) = cos²(t) + sin²(t) = 1')

# Plot dF/dt
plt.subplot(2, 2, 3)
plt.plot(t_vals, dF_vals, 'r-')
plt.grid(True)
plt.xlabel('t')
plt.ylabel('dF/dt')
plt.title('dF/dt = 0 (Constant Function)')

# Plot the individual terms in the Chain Rule
term1 = df_dx(x(t_vals), y(t_vals)) * dx_dt(t_vals)
term2 = df_dy(x(t_vals), y(t_vals)) * dy_dt(t_vals)

plt.subplot(2, 2, 4)
plt.plot(t_vals, term1, 'b-', label='(∂f/∂x)(dx/dt)')
plt.plot(t_vals, term2, 'g-', label='(∂f/∂y)(dy/dt)')
plt.plot(t_vals, term1 + term2, 'r--', label='Sum = dF/dt')
plt.grid(True)
plt.xlabel('t')
plt.ylabel('Terms')
plt.title('Chain Rule Terms')
plt.legend()

plt.tight_layout()
plt.show()
```

### Example 2: F(x, y) = f(u(x, y), v(x, y)) = u² + v²

Let u(x, y) = x + y and v(x, y) = x - y.

1. Compute ∂f/∂u = 2u and ∂f/∂v = 2v
2. Compute ∂u/∂x = 1, ∂u/∂y = 1, ∂v/∂x = 1, ∂v/∂y = -1
3. Apply the Chain Rule:
   - ∂F/∂x = (∂f/∂u)(∂u/∂x) + (∂f/∂v)(∂v/∂x) = 2u·1 + 2v·1 = 2(x + y) + 2(x - y) = 4x
   - ∂F/∂y = (∂f/∂u)(∂u/∂y) + (∂f/∂v)(∂v/∂y) = 2u·1 + 2v·(-1) = 2(x + y) - 2(x - y) = 4y

This makes sense because F(x, y) = (x + y)² + (x - y)² = 2x² + 2y², so ∂F/∂x = 4x and ∂F/∂y = 4y.

```python
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import sympy as sp

# Define the functions
def u(x, y):
    return x + y

def v(x, y):
    return x - y

def f(u, v):
    return u**2 + v**2

def F(x, y):
    return f(u(x, y), v(x, y))

# Compute the partial derivatives
def df_du(u, v):
    return 2*u

def df_dv(u, v):
    return 2*v

def du_dx(x, y):
    return 1

def du_dy(x, y):
    return 1

def dv_dx(x, y):
    return 1

def dv_dy(x, y):
    return -1

def dF_dx(x, y):
    return df_du(u(x, y), v(x, y)) * du_dx(x, y) + df_dv(u(x, y), v(x, y)) * dv_dx(x, y)

def dF_dy(x, y):
    return df_du(u(x, y), v(x, y)) * du_dy(x, y) + df_dv(u(x, y), v(x, y)) * dv_dy(x, y)

# Verify with symbolic differentiation
x_sym, y_sym = sp.symbols('x y')
u_sym = x_sym + y_sym
v_sym = x_sym - y_sym
f_sym = u_sym**2 + v_sym**2
F_sym = f_sym.subs([(sp.Symbol('u'), u_sym), (sp.Symbol('v'), v_sym)])
dF_dx_sym = sp.diff(F_sym, x_sym)
dF_dy_sym = sp.diff(F_sym, y_sym)

print(f"F(x, y) = {F_sym}")
print(f"∂F/∂x = {dF_dx_sym}")
print(f"∂F/∂y = {dF_dy_sym}")

# Create a grid of points
x = np.linspace(-2, 2, 50)
y = np.linspace(-2, 2, 50)
X, Y = np.meshgrid(x, y)
U = u(X, Y)
V = v(X, Y)
Z = F(X, Y)
dZ_dx = dF_dx(X, Y)
dZ_dy = dF_dy(X, Y)

# Create 3D plots
fig = plt.figure(figsize=(15, 10))

# Plot F(x, y) = (x + y)² + (x - y)²
ax1 = fig.add_subplot(221, projection='3d')
surf = ax1.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8, edgecolor='none')
ax1.set_xlabel('x')
ax1.set_ylabel('y')
ax1.set_zlabel('F(x, y)')
ax1.set_title('F(x, y) = (x + y)² + (x - y)²')

# Plot ∂F/∂x
ax2 = fig.add_subplot(222, projection='3d')
surf = ax2.plot_surface(X, Y, dZ_dx, cmap='plasma', alpha=0.8, edgecolor='none')
ax2.set_xlabel('x')
ax2.set_ylabel('y')
ax2.set_zlabel('∂F/∂x')
ax2.set_title('∂F/∂x = 4x')

# Plot ∂F/∂y
ax3 = fig.add_subplot(223, projection='3d')
surf = ax3.plot_surface(X, Y, dZ_dy, cmap='inferno', alpha=0.8, edgecolor='none')
ax3.set_xlabel('x')
ax3.set_ylabel('y')
ax3.set_zlabel('∂F/∂y')
ax3.set_title('∂F/∂y = 4y')

# Plot the gradient field
ax4 = fig.add_subplot(224)
ax4.contour(X, Y, Z, 20, cmap='viridis')
ax4.quiver(X[::3, ::3], Y[::3, ::3], dZ_dx[::3, ::3], dZ_dy[::3, ::3], 
           scale=50, color='r', alpha=0.7)
ax4.set_xlabel('x')
ax4.set_ylabel('y')
ax4.set_title('Gradient Field: ∇F(x, y) = (4x, 4y)')
ax4.grid(True)

plt.tight_layout()
plt.show()
```

## The Chain Rule in Vector Calculus

In vector calculus, the Chain Rule can be expressed using the gradient operator ∇.

For a scalar-valued function f(g(x)), where g is a vector-valued function, the gradient of f with respect to x is:

$$\nabla_x f = J_g^T \nabla_g f$$

where J_g is the Jacobian matrix of g with respect to x, and ∇_g f is the gradient of f with respect to g.

This form of the Chain Rule is particularly useful in machine learning for computing gradients in neural networks.

## Applications in Machine Learning

### 1. Gradient Descent in Multiple Dimensions

In gradient descent, we update parameters in the direction of steepest descent:

$$\theta_{t+1} = \theta_t - \alpha \nabla_\theta L(\theta_t)$$

When the loss function L is a composition of functions (as in neural networks), we use the Chain Rule to compute the gradient.

```python
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Define a loss function L(θ₁, θ₂) = (θ₁² + θ₂ - 11)² + (θ₁ + θ₂² - 7)²
# This is the Himmelblau function, which has multiple local minima
def loss(theta1, theta2):
    return (theta1**2 + theta2 - 11)**2 + (theta1 + theta2**2 - 7)**2

# Compute the gradient using the Chain Rule
def grad_loss(theta1, theta2):
    dL_dtheta1 = 2*(theta1**2 + theta2 - 11)*(2*theta1) + 2*(theta1 + theta2**2 - 7)
    dL_dtheta2 = 2*(theta1**2 + theta2 - 11) + 2*(theta1 + theta2**2 - 7)*(2*theta2)
    return np.array([dL_dtheta1, dL_dtheta2])

# Implement gradient descent
def gradient_descent(start_theta1, start_theta2, learning_rate=0.01, n_iterations=1000):
    theta1, theta2 = start_theta1, start_theta2
    path = [(theta1, theta2)]
    
    for _ in range(n_iterations):
        grad = grad_loss(theta1, theta2)
        theta1 = theta1 - learning_rate * grad[0]
        theta2 = theta2 - learning_rate * grad[1]
        path.append((theta1, theta2))
    
    return np.array(path)

# Run gradient descent from different starting points
start_points = [(0, 0), (3, 3), (-3, 3), (3, -3), (-3, -3)]
paths = [gradient_descent(x0, y0, learning_rate=0.01, n_iterations=1000) for x0, y0 in start_points]

# Create a grid of points for the contour plot
theta1 = np.linspace(-5, 5, 100)
theta2 = np.linspace(-5, 5, 100)
Theta1, Theta2 = np.meshgrid(theta1, theta2)
Z = loss(Theta1, Theta2)

# Create 3D surface plot
fig = plt.figure(figsize=(15, 10))
ax1 = fig.add_subplot(121, projection='3d')
surf = ax1.plot_surface(Theta1, Theta2, Z, cmap='viridis', alpha=0.8, edgecolor='none')
for path in paths:
    ax1.plot(path[:, 0], path[:, 1], [loss(x, y) for x, y in path], 'r-o', markersize=3)
ax1.set_xlabel('θ₁')
ax1.set_ylabel('θ₂')
ax1.set_zlabel('L(θ₁, θ₂)')
ax1.set_title('Gradient Descent on Loss Surface')

# Create contour plot
ax2 = fig.add_subplot(122)
contour = ax2.contour(Theta1, Theta2, Z, 50, cmap='viridis')
plt.colorbar(contour, ax=ax2)
for path in paths:
    ax2.plot(path[:, 0], path[:, 1], 'r-o', markersize=3)
    ax2.annotate('Start', (path[0, 0], path[0, 1]), xytext=(10, 10), 
                textcoords='offset points', color='blue')
    ax2.annotate('End', (path[-1, 0], path[-1, 1]), xytext=(10, -10), 
                textcoords='offset points', color='green')
ax2.set_xlabel('θ₁')
ax2.set_ylabel('θ₂')
ax2.set_title('Gradient Descent Paths on Contour Plot')
ax2.grid(True)

plt.tight_layout()
plt.show()
```

### 2. Neural Network Training

In neural networks, the loss function is a composition of many functions (activation functions, weight multiplications, etc.). The Chain Rule is used to compute the gradient of the loss with respect to each weight and bias.

```python
import numpy as np
import matplotlib.pyplot as plt

# Define a simple neural network with one hidden layer
class SimpleNN:
    def __init__(self, input_size, hidden_size, output_size):
        # Initialize weights and biases
        self.W1 = np.random.randn(input_size, hidden_size) * 0.01
        self.b1 = np.zeros((1, hidden_size))
        self.W2 = np.random.randn(hidden_size, output_size) * 0.01
        self.b2 = np.zeros((1, output_size))
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-np.clip(x, -30, 30)))  # Clip to avoid overflow
    
    def forward(self, X):
        # Forward pass
        self.z1 = np.dot(X, self.W1) + self.b1
        self.a1 = self.sigmoid(self.z1)
        self.z2 = np.dot(self.a1, self.W2) + self.b2
        self.a2 = self.sigmoid(self.z2)
        return self.a2
    
    def compute_loss(self, y_pred, y_true):
        # Binary cross-entropy loss
        m = y_true.shape[0]
        loss = -np.sum(y_true * np.log(y_pred + 1e-15) + (1 - y_true) * np.log(1 - y_pred + 1e-15)) / m
        return loss
    
    def backward(self, X, y):
        # Backward pass (using the Chain Rule)
        m = X.shape[0]
        
        # Output layer
        dz2 = self.a2 - y  # Derivative of loss with respect to z2
        dW2 = np.dot(self.a1.T, dz2) / m  # Chain Rule: dL/dW2 = dL/dz2 * dz2/dW2
        db2 = np.sum(dz2, axis=0, keepdims=True) / m  # Chain Rule: dL/db2 = dL/dz2 * dz2/db2
        
        # Hidden layer
        da1 = np.dot(dz2, self.W2.T)  # Chain Rule: dL/da1 = dL/dz2 * dz2/da1
        dz1 = da1 * self.a1 * (1 - self.a1)  # Chain Rule: dL/dz1 = dL/da1 * da1/dz1 (derivative of sigmoid)
        dW1 = np.dot(X.T, dz1) / m  # Chain Rule: dL/dW1 = dL/dz1 * dz1/dW1
        db1 = np.sum(dz1, axis=0, keepdims=True) / m  # Chain Rule: dL/db1 = dL/dz1 * dz1/db1
        
        return dW1, db1, dW2, db2
    
    def update_parameters(self, dW1, db1, dW2, db2, learning_rate):
        # Update weights and biases using gradient descent
        self.W1 -= learning_rate * dW1
        self.b1 -= learning_rate * db1
        self.W2 -= learning_rate * dW2
        self.b2 -= learning_rate * db2
    
    def train(self, X, y, learning_rate=0.1, n_iterations=1000):
        losses = []
        
        for i in range(n_iterations):
            # Forward pass
            y_pred = self.forward(X)
            
            # Compute loss
            loss = self.compute_loss(y_pred, y)
            losses.append(loss)
            
            # Backward pass (using the Chain Rule)
            dW1, db1, dW2, db2 = self.backward(X, y)
            
            # Update parameters
            self.update_parameters(dW1, db1, dW2, db2, learning_rate)
            
            # Print progress
            if i % 100 == 0:
                print(f"Iteration {i}, Loss: {loss}")
        
        return losses

# Generate synthetic data for binary classification (XOR problem)
X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([[0], [1], [1], [0]])

# Create and train the neural network
nn = SimpleNN(input_size=2, hidden_size=4, output_size=1)
losses = nn.train(X, y, learning_rate=0.5, n_iterations=10000)

# Plot the loss curve
plt.figure(figsize=(10, 6))
plt.plot(losses)
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.title('Training Loss')
plt.grid(True)
plt.tight_layout()
plt.show()

# Visualize the decision boundary
plt.figure(figsize=(10, 8))

# Create a grid of points
x_min, x_max = -0.5, 1.5
y_min, y_max = -0.5, 1.5
xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                     np.linspace(y_min, y_max, 100))
grid_points = np.c_[xx.ravel(), yy.ravel()]

# Make predictions on the grid
Z = nn.forward(grid_points)
Z = Z.reshape(xx.shape)

# Plot the decision boundary and data points
plt.contourf(xx, yy, Z, alpha=0.8, cmap='viridis')
plt.scatter(X[:, 0], X[:, 1], c=y.flatten(), cmap='coolwarm', edgecolors='k', s=100)
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('Neural Network Decision Boundary for XOR Problem')
plt.colorbar(label='Probability')
plt.grid(True)
plt.tight_layout()
plt.show()
```

## Summary

In this section, we've covered:

1. **Chain Rule for Functions of Multiple Variables**: How to compute derivatives of composite functions with multiple inputs and intermediate variables
2. **The Jacobian Matrix**: A general form of the Chain Rule for vector-valued functions
3. **Examples**: Applying the multivariate Chain Rule to specific functions
4. **Applications in Machine Learning**: Gradient descent in multiple dimensions and neural network training

The multivariate Chain Rule is a powerful tool that allows us to compute gradients in complex models with many parameters, which is essential for training machine learning models. In the next section, we'll explore computational graphs, which provide a visual representation of function compositions and help us understand how the Chain Rule is applied in practice.

## References

1. Deisenroth, M. P., Faisal, A. A., & Ong, C. S. (2020). Mathematics for Machine Learning. Cambridge University Press.
2. Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.
3. Stewart, J. (2015). Calculus: Early Transcendentals (8th ed.). Cengage Learning.
4. Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.
