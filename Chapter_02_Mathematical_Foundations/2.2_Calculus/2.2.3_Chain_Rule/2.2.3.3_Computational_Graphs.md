# 2.2.3.3 Computational Graphs

## Introduction to Computational Graphs

Computational graphs are a powerful way to visualize and understand complex mathematical expressions, particularly those involving multiple compositions of functions. They are especially useful in machine learning for representing the flow of computations in models like neural networks and for implementing automatic differentiation.

A computational graph is a directed graph where:
- Nodes represent variables (inputs, outputs, or intermediate values)
- Edges represent operations or functions that transform variables
- The flow of computation follows the direction of the edges

## Basic Structure of Computational Graphs

### Example: Simple Expression

Let's consider a simple expression: f(x, y) = (x + y) * (x - y)

We can represent this as a computational graph:

```
    x       y
    |       |
    +-------+
    |       |
    v       v
    +       -
    |       |
    v       v
    a=x+y   b=x-y
    |       |
    +-------+
        |
        v
        *
        |
        v
        f=a*b
```

In this graph:
- x and y are input variables
- a = x + y and b = x - y are intermediate variables
- f = a * b is the output variable

### Example: More Complex Expression

Let's consider a more complex expression: f(x, y, z) = (x + y)² * sin(z / (x - y))

The computational graph would be:

```
    x       y       z
    |       |       |
    +-------+       |
    |       |       |
    v       v       |
    +       -       |
    |       |       |
    v       |       |
    a=x+y   |       |
    |       |       |
    v       v       v
    ^2      /       |
    |       |       |
    v       v       |
    c=a²    d=z/(x-y)
    |       |
    |       v
    |       sin
    |       |
    |       v
    |       e=sin(d)
    |       |
    +-------+
        |
        v
        *
        |
        v
        f=c*e
```

## Forward and Backward Passes

Computational graphs are particularly useful for understanding the two main phases of computation in machine learning:

1. **Forward Pass**: Computing the output of the model given the inputs
2. **Backward Pass**: Computing the gradients of the output with respect to the inputs and parameters

### Forward Pass

In the forward pass, we compute the value of each node in the graph, starting from the inputs and moving towards the output.

For our simple example f(x, y) = (x + y) * (x - y):
1. Compute a = x + y
2. Compute b = x - y
3. Compute f = a * b

### Backward Pass

In the backward pass, we compute the gradients of the output with respect to each node in the graph, starting from the output and moving backwards towards the inputs. This is where the Chain Rule comes into play.

For our simple example:
1. Compute ∂f/∂a = b and ∂f/∂b = a
2. Compute ∂f/∂x = (∂f/∂a)(∂a/∂x) + (∂f/∂b)(∂b/∂x) = b*1 + a*1 = b + a
3. Compute ∂f/∂y = (∂f/∂a)(∂a/∂y) + (∂f/∂b)(∂b/∂y) = b*1 + a*(-1) = b - a

## Implementing Computational Graphs in Python

Let's implement a simple computational graph framework in Python:

```python
import numpy as np
import matplotlib.pyplot as plt
import networkx as nx

class Node:
    def __init__(self, name):
        self.name = name
        self.value = None
        self.gradient = None
        self.parents = []
        self.operation = None
    
    def forward(self):
        raise NotImplementedError
    
    def backward(self):
        raise NotImplementedError

class InputNode(Node):
    def __init__(self, name, value=None):
        super().__init__(name)
        self.value = value
    
    def forward(self):
        # Input nodes already have their values set
        pass
    
    def backward(self):
        # Gradient is already computed for input nodes
        pass

class AddNode(Node):
    def __init__(self, name, parent1, parent2):
        super().__init__(name)
        self.parents = [parent1, parent2]
        self.operation = "+"
    
    def forward(self):
        self.value = self.parents[0].value + self.parents[1].value
    
    def backward(self):
        # Derivative of addition with respect to each input is 1
        for parent in self.parents:
            if parent.gradient is None:
                parent.gradient = 0
            parent.gradient += 1.0 * self.gradient

class SubtractNode(Node):
    def __init__(self, name, parent1, parent2):
        super().__init__(name)
        self.parents = [parent1, parent2]
        self.operation = "-"
    
    def forward(self):
        self.value = self.parents[0].value - self.parents[1].value
    
    def backward(self):
        # Derivative of subtraction with respect to first input is 1
        if self.parents[0].gradient is None:
            self.parents[0].gradient = 0
        self.parents[0].gradient += 1.0 * self.gradient
        
        # Derivative of subtraction with respect to second input is -1
        if self.parents[1].gradient is None:
            self.parents[1].gradient = 0
        self.parents[1].gradient += -1.0 * self.gradient

class MultiplyNode(Node):
    def __init__(self, name, parent1, parent2):
        super().__init__(name)
        self.parents = [parent1, parent2]
        self.operation = "*"
    
    def forward(self):
        self.value = self.parents[0].value * self.parents[1].value
    
    def backward(self):
        # Derivative of multiplication with respect to first input is the second input
        if self.parents[0].gradient is None:
            self.parents[0].gradient = 0
        self.parents[0].gradient += self.parents[1].value * self.gradient
        
        # Derivative of multiplication with respect to second input is the first input
        if self.parents[1].gradient is None:
            self.parents[1].gradient = 0
        self.parents[1].gradient += self.parents[0].value * self.gradient

class DivideNode(Node):
    def __init__(self, name, parent1, parent2):
        super().__init__(name)
        self.parents = [parent1, parent2]
        self.operation = "/"
    
    def forward(self):
        self.value = self.parents[0].value / self.parents[1].value
    
    def backward(self):
        # Derivative of division with respect to numerator is 1/denominator
        if self.parents[0].gradient is None:
            self.parents[0].gradient = 0
        self.parents[0].gradient += (1.0 / self.parents[1].value) * self.gradient
        
        # Derivative of division with respect to denominator is -numerator/denominator^2
        if self.parents[1].gradient is None:
            self.parents[1].gradient = 0
        self.parents[1].gradient += (-self.parents[0].value / (self.parents[1].value ** 2)) * self.gradient

class PowerNode(Node):
    def __init__(self, name, parent, exponent):
        super().__init__(name)
        self.parents = [parent]
        self.exponent = exponent
        self.operation = f"^{exponent}"
    
    def forward(self):
        self.value = self.parents[0].value ** self.exponent
    
    def backward(self):
        # Derivative of x^n with respect to x is n*x^(n-1)
        if self.parents[0].gradient is None:
            self.parents[0].gradient = 0
        self.parents[0].gradient += self.exponent * (self.parents[0].value ** (self.exponent - 1)) * self.gradient

class SinNode(Node):
    def __init__(self, name, parent):
        super().__init__(name)
        self.parents = [parent]
        self.operation = "sin"
    
    def forward(self):
        self.value = np.sin(self.parents[0].value)
    
    def backward(self):
        # Derivative of sin(x) with respect to x is cos(x)
        if self.parents[0].gradient is None:
            self.parents[0].gradient = 0
        self.parents[0].gradient += np.cos(self.parents[0].value) * self.gradient

class ComputationalGraph:
    def __init__(self):
        self.nodes = []
    
    def add_node(self, node):
        self.nodes.append(node)
        return node
    
    def forward(self):
        # Topological sort (simple version assuming nodes are added in order)
        for node in self.nodes:
            node.forward()
    
    def backward(self, output_node):
        # Initialize gradient of output node to 1
        output_node.gradient = 1.0
        
        # Reverse topological sort
        for node in reversed(self.nodes):
            node.backward()
    
    def visualize(self):
        G = nx.DiGraph()
        
        # Add nodes
        for node in self.nodes:
            label = f"{node.name}\nvalue: {node.value:.4f}"
            if node.gradient is not None:
                label += f"\ngradient: {node.gradient:.4f}"
            G.add_node(node.name, label=label)
        
        # Add edges
        for node in self.nodes:
            if hasattr(node, 'parents') and node.parents:
                for parent in node.parents:
                    G.add_edge(parent.name, node.name, operation=node.operation)
        
        # Draw the graph
        plt.figure(figsize=(12, 8))
        pos = nx.spring_layout(G, seed=42)
        
        # Draw nodes
        nx.draw_networkx_nodes(G, pos, node_size=3000, node_color='lightblue', alpha=0.8)
        
        # Draw edges
        nx.draw_networkx_edges(G, pos, width=2, alpha=0.7, arrows=True, arrowsize=20)
        
        # Draw labels
        node_labels = nx.get_node_attributes(G, 'label')
        nx.draw_networkx_labels(G, pos, labels=node_labels, font_size=10)
        
        # Draw edge labels
        edge_labels = nx.get_edge_attributes(G, 'operation')
        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=12)
        
        plt.axis('off')
        plt.title('Computational Graph')
        plt.tight_layout()
        plt.show()

# Example: f(x, y) = (x + y) * (x - y)
def example1():
    graph = ComputationalGraph()
    
    # Input nodes
    x = graph.add_node(InputNode("x", 3.0))
    y = graph.add_node(InputNode("y", 2.0))
    
    # Intermediate nodes
    a = graph.add_node(AddNode("a", x, y))
    b = graph.add_node(SubtractNode("b", x, y))
    
    # Output node
    f = graph.add_node(MultiplyNode("f", a, b))
    
    # Forward pass
    graph.forward()
    print(f"f({x.value}, {y.value}) = {f.value}")
    
    # Backward pass
    graph.backward(f)
    print(f"∂f/∂x = {x.gradient}")
    print(f"∂f/∂y = {y.gradient}")
    
    # Visualize the graph
    graph.visualize()

# Example: f(x, y, z) = (x + y)² * sin(z / (x - y))
def example2():
    graph = ComputationalGraph()
    
    # Input nodes
    x = graph.add_node(InputNode("x", 3.0))
    y = graph.add_node(InputNode("y", 2.0))
    z = graph.add_node(InputNode("z", 1.0))
    
    # Intermediate nodes
    a = graph.add_node(AddNode("a", x, y))
    b = graph.add_node(SubtractNode("b", x, y))
    c = graph.add_node(PowerNode("c", a, 2))
    d = graph.add_node(DivideNode("d", z, b))
    e = graph.add_node(SinNode("e", d))
    
    # Output node
    f = graph.add_node(MultiplyNode("f", c, e))
    
    # Forward pass
    graph.forward()
    print(f"f({x.value}, {y.value}, {z.value}) = {f.value}")
    
    # Backward pass
    graph.backward(f)
    print(f"∂f/∂x = {x.gradient}")
    print(f"∂f/∂y = {y.gradient}")
    print(f"∂f/∂z = {z.gradient}")
    
    # Visualize the graph
    graph.visualize()

# Run the examples
print("Example 1: f(x, y) = (x + y) * (x - y)")
example1()

print("\nExample 2: f(x, y, z) = (x + y)² * sin(z / (x - y))")
example2()
```

## Computational Graphs in Neural Networks

Neural networks can be represented as computational graphs, where:
- Input nodes represent the input features
- Intermediate nodes represent hidden layers and activation functions
- Output nodes represent the predictions
- Additional nodes represent the loss function

### Example: Simple Neural Network

Let's consider a simple neural network with one hidden layer:

```
    x₁      x₂      (inputs)
    |       |
    +-------+-------+
    |       |       |
    v       v       v
    w₁₁     w₁₂     w₁₃
    |       |       |
    v       v       v
    *       *       *
    |       |       |
    +-------+-------+
    |
    v
    sum + b₁
    |
    v
    sigmoid
    |
    v
    h       (hidden layer)
    |
    +-------+
    |       |
    v       v
    w₂₁     w₂₂
    |       |
    v       v
    *       *
    |       |
    +-------+
    |
    v
    sum + b₂
    |
    v
    sigmoid
    |
    v
    y_pred  (output)
    |
    +-------+
    |       |
    v       v
    y_pred  y_true
    |       |
    +-------+
    |
    v
    loss
```

## Automatic Differentiation

Computational graphs are the foundation of automatic differentiation, which is a technique for automatically computing derivatives in machine learning frameworks like TensorFlow and PyTorch.

There are two main approaches to automatic differentiation:

1. **Forward Mode**: Computes the derivative of intermediate variables with respect to inputs as the computation moves forward
2. **Reverse Mode**: Computes the derivative of the output with respect to intermediate variables as the computation moves backward (this is what's used in backpropagation)

### Example: Reverse Mode Automatic Differentiation

Let's implement a simple example of reverse mode automatic differentiation:

```python
import numpy as np
import matplotlib.pyplot as plt

# Define a simple neural network with one hidden layer
class SimpleNN:
    def __init__(self, input_size, hidden_size, output_size):
        # Initialize weights and biases
        self.W1 = np.random.randn(input_size, hidden_size) * 0.01
        self.b1 = np.zeros((1, hidden_size))
        self.W2 = np.random.randn(hidden_size, output_size) * 0.01
        self.b2 = np.zeros((1, output_size))
        
        # Cache for storing intermediate values
        self.cache = {}
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-np.clip(x, -30, 30)))  # Clip to avoid overflow
    
    def forward(self, X):
        # Store the computational graph in the cache
        self.cache['X'] = X
        
        # First layer
        self.cache['z1'] = np.dot(X, self.W1) + self.b1
        self.cache['a1'] = self.sigmoid(self.cache['z1'])
        
        # Second layer
        self.cache['z2'] = np.dot(self.cache['a1'], self.W2) + self.b2
        self.cache['a2'] = self.sigmoid(self.cache['z2'])
        
        return self.cache['a2']
    
    def compute_loss(self, y_pred, y_true):
        # Binary cross-entropy loss
        m = y_true.shape[0]
        loss = -np.sum(y_true * np.log(y_pred + 1e-15) + (1 - y_true) * np.log(1 - y_pred + 1e-15)) / m
        
        # Store in cache
        self.cache['y_true'] = y_true
        self.cache['loss'] = loss
        
        return loss
    
    def backward(self):
        # Get values from cache
        X = self.cache['X']
        a1 = self.cache['a1']
        a2 = self.cache['a2']
        y_true = self.cache['y_true']
        m = X.shape[0]
        
        # Initialize gradients
        gradients = {}
        
        # Output layer
        dz2 = a2 - y_true  # Derivative of loss with respect to z2
        gradients['dW2'] = np.dot(a1.T, dz2) / m  # Chain Rule: dL/dW2 = dL/dz2 * dz2/dW2
        gradients['db2'] = np.sum(dz2, axis=0, keepdims=True) / m  # Chain Rule: dL/db2 = dL/dz2 * dz2/db2
        
        # Hidden layer
        da1 = np.dot(dz2, self.W2.T)  # Chain Rule: dL/da1 = dL/dz2 * dz2/da1
        dz1 = da1 * a1 * (1 - a1)  # Chain Rule: dL/dz1 = dL/da1 * da1/dz1 (derivative of sigmoid)
        gradients['dW1'] = np.dot(X.T, dz1) / m  # Chain Rule: dL/dW1 = dL/dz1 * dz1/dW1
        gradients['db1'] = np.sum(dz1, axis=0, keepdims=True) / m  # Chain Rule: dL/db1 = dL/dz1 * dz1/db1
        
        return gradients
    
    def update_parameters(self, gradients, learning_rate):
        # Update weights and biases using gradient descent
        self.W1 -= learning_rate * gradients['dW1']
        self.b1 -= learning_rate * gradients['db1']
        self.W2 -= learning_rate * gradients['dW2']
        self.b2 -= learning_rate * gradients['db2']
    
    def train(self, X, y, learning_rate=0.1, n_iterations=1000):
        losses = []
        
        for i in range(n_iterations):
            # Forward pass
            y_pred = self.forward(X)
            
            # Compute loss
            loss = self.compute_loss(y_pred, y)
            losses.append(loss)
            
            # Backward pass (using automatic differentiation)
            gradients = self.backward()
            
            # Update parameters
            self.update_parameters(gradients, learning_rate)
            
            # Print progress
            if i % 100 == 0:
                print(f"Iteration {i}, Loss: {loss}")
        
        return losses

# Generate synthetic data for binary classification (XOR problem)
X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([[0], [1], [1], [0]])

# Create and train the neural network
nn = SimpleNN(input_size=2, hidden_size=4, output_size=1)
losses = nn.train(X, y, learning_rate=0.5, n_iterations=10000)

# Plot the loss curve
plt.figure(figsize=(10, 6))
plt.plot(losses)
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.title('Training Loss')
plt.grid(True)
plt.tight_layout()
plt.show()

# Visualize the decision boundary
plt.figure(figsize=(10, 8))

# Create a grid of points
x_min, x_max = -0.5, 1.5
y_min, y_max = -0.5, 1.5
xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                     np.linspace(y_min, y_max, 100))
grid_points = np.c_[xx.ravel(), yy.ravel()]

# Make predictions on the grid
Z = nn.forward(grid_points)
Z = Z.reshape(xx.shape)

# Plot the decision boundary and data points
plt.contourf(xx, yy, Z, alpha=0.8, cmap='viridis')
plt.scatter(X[:, 0], X[:, 1], c=y.flatten(), cmap='coolwarm', edgecolors='k', s=100)
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('Neural Network Decision Boundary for XOR Problem')
plt.colorbar(label='Probability')
plt.grid(True)
plt.tight_layout()
plt.show()
```

## Computational Graphs in Deep Learning Frameworks

Modern deep learning frameworks like TensorFlow and PyTorch use computational graphs to represent models and automatically compute gradients.

### TensorFlow

TensorFlow 2.x uses eager execution by default, but it still builds computational graphs behind the scenes for automatic differentiation.

```python
import tensorflow as tf
import matplotlib.pyplot as plt

# Define a simple model using TensorFlow
class SimpleNNTF(tf.keras.Model):
    def __init__(self, hidden_size):
        super(SimpleNNTF, self).__init__()
        self.dense1 = tf.keras.layers.Dense(hidden_size, activation='sigmoid')
        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')
    
    def call(self, inputs):
        x = self.dense1(inputs)
        return self.dense2(x)

# Generate synthetic data for binary classification (XOR problem)
X = tf.constant([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=tf.float32)
y = tf.constant([[0], [1], [1], [0]], dtype=tf.float32)

# Create and compile the model
model = SimpleNNTF(hidden_size=4)
model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.5),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(X, y, epochs=1000, verbose=0)

# Plot the loss curve
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'])
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss')
plt.grid(True)
plt.tight_layout()
plt.show()

# Visualize the decision boundary
plt.figure(figsize=(10, 8))

# Create a grid of points
x_min, x_max = -0.5, 1.5
y_min, y_max = -0.5, 1.5
xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                     np.linspace(y_min, y_max, 100))
grid_points = np.c_[xx.ravel(), yy.ravel()]

# Make predictions on the grid
Z = model.predict(grid_points, verbose=0)
Z = Z.reshape(xx.shape)

# Plot the decision boundary and data points
plt.contourf(xx, yy, Z, alpha=0.8, cmap='viridis')
plt.scatter(X[:, 0], X[:, 1], c=y.numpy().flatten(), cmap='coolwarm', edgecolors='k', s=100)
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('TensorFlow Neural Network Decision Boundary for XOR Problem')
plt.colorbar(label='Probability')
plt.grid(True)
plt.tight_layout()
plt.show()
```

### PyTorch

PyTorch uses dynamic computational graphs, which are built on-the-fly during the forward pass.

```python
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt

# Define a simple model using PyTorch
class SimpleNNPyTorch(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleNNPyTorch, self).__init__()
        self.layer1 = nn.Linear(input_size, hidden_size)
        self.sigmoid1 = nn.Sigmoid()
        self.layer2 = nn.Linear(hidden_size, output_size)
        self.sigmoid2 = nn.Sigmoid()
    
    def forward(self, x):
        x = self.layer1(x)
        x = self.sigmoid1(x)
        x = self.layer2(x)
        x = self.sigmoid2(x)
        return x

# Generate synthetic data for binary classification (XOR problem)
X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)
y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)

# Create the model
model = SimpleNNPyTorch(input_size=2, hidden_size=4, output_size=1)

# Define loss function and optimizer
criterion = nn.BCELoss()
optimizer = optim.SGD(model.parameters(), lr=0.5)

# Train the model
losses = []
for epoch in range(1000):
    # Forward pass
    outputs = model(X)
    loss = criterion(outputs, y)
    losses.append(loss.item())
    
    # Backward pass and optimize
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    if (epoch+1) % 100 == 0:
        print(f'Epoch [{epoch+1}/1000], Loss: {loss.item():.4f}')

# Plot the loss curve
plt.figure(figsize=(10, 6))
plt.plot(losses)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss')
plt.grid(True)
plt.tight_layout()
plt.show()

# Visualize the decision boundary
plt.figure(figsize=(10, 8))

# Create a grid of points
x_min, x_max = -0.5, 1.5
y_min, y_max = -0.5, 1.5
xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                     np.linspace(y_min, y_max, 100))
grid_points = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)

# Make predictions on the grid
with torch.no_grad():
    Z = model(grid_points).numpy()
Z = Z.reshape(xx.shape)

# Plot the decision boundary and data points
plt.contourf(xx, yy, Z, alpha=0.8, cmap='viridis')
plt.scatter(X[:, 0], X[:, 1], c=y.numpy().flatten(), cmap='coolwarm', edgecolors='k', s=100)
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('PyTorch Neural Network Decision Boundary for XOR Problem')
plt.colorbar(label='Probability')
plt.grid(True)
plt.tight_layout()
plt.show()
```

## Summary

In this section, we've covered:

1. **Computational Graphs**: A visual representation of mathematical expressions as directed graphs
2. **Forward and Backward Passes**: How values and gradients flow through the graph
3. **Implementation**: Building a simple computational graph framework in Python
4. **Neural Networks**: Representing neural networks as computational graphs
5. **Automatic Differentiation**: Using computational graphs to automatically compute derivatives
6. **Deep Learning Frameworks**: How TensorFlow and PyTorch use computational graphs

Computational graphs provide a powerful abstraction for understanding and implementing complex mathematical operations, particularly in machine learning. They make it easier to visualize the flow of computation and to implement automatic differentiation, which is essential for training neural networks efficiently.

## References

1. Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.
2. Baydin, A. G., Pearlmutter, B. A., Radul, A. A., & Siskind, J. M. (2018). Automatic differentiation in machine learning: a survey. Journal of Machine Learning Research, 18(153), 1-43.
3. Abadi, M., et al. (2016). TensorFlow: A system for large-scale machine learning. In 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16) (pp. 265-283).
4. Paszke, A., et al. (2019). PyTorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems (pp. 8026-8037).
